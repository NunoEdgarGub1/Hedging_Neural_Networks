{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# Append the library path to PYTHONPATH, so library can be imported.\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from library import plot, bs\n",
    "from library import network as nw\n",
    "from library import common as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Normal data sets!\n",
      "\n",
      "Load and clean the training and validation data.\n",
      "Original data size is 640874\n",
      "We remove in-the-money samples. 323786 samples (50.52%) are removed. We have 49.48% of original data left, yielding a size of 317088.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.48% of original data left, yielding a size of 317088.\n",
      "We remove samples when S1 is not available. 2929 samples (0.92%) are removed. We have 49.02% of original data left, yielding a size of 314159.\n",
      "\n",
      "\n",
      "====================\n",
      "Clean and load all Monte Carlo test data.\n",
      "\n",
      "Load Monte Carlo set 1\n",
      "We remove in-the-money samples. 84872 samples (51.03%) are removed. We have 48.97% of original data left, yielding a size of 81436.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 48.97% of original data left, yielding a size of 81436.\n",
      "We remove samples when S1 is not available. 3225 samples (3.96%) are removed. We have 47.03% of original data left, yielding a size of 78211.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 2\n",
      "We remove in-the-money samples. 75770 samples (50.25%) are removed. We have 49.75% of original data left, yielding a size of 75009.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.75% of original data left, yielding a size of 75009.\n",
      "We remove samples when S1 is not available. 2308 samples (3.08%) are removed. We have 48.22% of original data left, yielding a size of 72701.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 3\n",
      "We remove in-the-money samples. 75946 samples (50.24%) are removed. We have 49.76% of original data left, yielding a size of 75225.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.76% of original data left, yielding a size of 75225.\n",
      "We remove samples when S1 is not available. 2287 samples (3.04%) are removed. We have 48.25% of original data left, yielding a size of 72938.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 4\n",
      "We remove in-the-money samples. 77974 samples (50.37%) are removed. We have 49.63% of original data left, yielding a size of 76815.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.63% of original data left, yielding a size of 76815.\n",
      "We remove samples when S1 is not available. 2323 samples (3.02%) are removed. We have 48.12% of original data left, yielding a size of 74492.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 5\n",
      "We remove in-the-money samples. 72253 samples (50.10%) are removed. We have 49.90% of original data left, yielding a size of 71954.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.90% of original data left, yielding a size of 71954.\n",
      "We remove samples when S1 is not available. 2154 samples (2.99%) are removed. We have 48.40% of original data left, yielding a size of 69800.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 6\n",
      "We remove in-the-money samples. 70813 samples (50.08%) are removed. We have 49.92% of original data left, yielding a size of 70599.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.92% of original data left, yielding a size of 70599.\n",
      "We remove samples when S1 is not available. 1927 samples (2.73%) are removed. We have 48.56% of original data left, yielding a size of 68672.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 7\n",
      "We remove in-the-money samples. 72014 samples (50.11%) are removed. We have 49.89% of original data left, yielding a size of 71698.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.89% of original data left, yielding a size of 71698.\n",
      "We remove samples when S1 is not available. 1985 samples (2.77%) are removed. We have 48.51% of original data left, yielding a size of 69713.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 8\n",
      "We remove in-the-money samples. 74437 samples (50.41%) are removed. We have 49.59% of original data left, yielding a size of 73227.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.59% of original data left, yielding a size of 73227.\n",
      "We remove samples when S1 is not available. 2110 samples (2.88%) are removed. We have 48.16% of original data left, yielding a size of 71117.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 9\n",
      "We remove in-the-money samples. 75740 samples (50.50%) are removed. We have 49.50% of original data left, yielding a size of 74233.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.50% of original data left, yielding a size of 74233.\n",
      "We remove samples when S1 is not available. 2380 samples (3.21%) are removed. We have 47.91% of original data left, yielding a size of 71853.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 10\n",
      "We remove in-the-money samples. 79043 samples (50.65%) are removed. We have 49.35% of original data left, yielding a size of 77002.\n",
      "We shrink moneyness range. 2130 samples (2.77%) are removed. We have 47.98% of original data left, yielding a size of 74872.\n",
      "We remove samples when S1 is not available. 2201 samples (2.94%) are removed. We have 46.57% of original data left, yielding a size of 72671.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 11\n",
      "We remove in-the-money samples. 74010 samples (50.33%) are removed. We have 49.67% of original data left, yielding a size of 73053.\n",
      "We shrink moneyness range. 368 samples (0.50%) are removed. We have 49.42% of original data left, yielding a size of 72685.\n",
      "We remove samples when S1 is not available. 2453 samples (3.37%) are removed. We have 47.76% of original data left, yielding a size of 70232.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 12\n",
      "We remove in-the-money samples. 74122 samples (50.19%) are removed. We have 49.81% of original data left, yielding a size of 73561.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.81% of original data left, yielding a size of 73561.\n",
      "We remove samples when S1 is not available. 2127 samples (2.89%) are removed. We have 48.37% of original data left, yielding a size of 71434.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 13\n",
      "We remove in-the-money samples. 82939 samples (50.82%) are removed. We have 49.18% of original data left, yielding a size of 80258.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.18% of original data left, yielding a size of 80258.\n",
      "We remove samples when S1 is not available. 2839 samples (3.54%) are removed. We have 47.44% of original data left, yielding a size of 77419.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 14\n",
      "We remove in-the-money samples. 73114 samples (50.20%) are removed. We have 49.80% of original data left, yielding a size of 72523.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.80% of original data left, yielding a size of 72523.\n",
      "We remove samples when S1 is not available. 2059 samples (2.84%) are removed. We have 48.38% of original data left, yielding a size of 70464.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 15\n",
      "We remove in-the-money samples. 75325 samples (50.32%) are removed. We have 49.68% of original data left, yielding a size of 74371.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.68% of original data left, yielding a size of 74371.\n",
      "We remove samples when S1 is not available. 2098 samples (2.82%) are removed. We have 48.28% of original data left, yielding a size of 72273.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 16\n",
      "We remove in-the-money samples. 74038 samples (50.15%) are removed. We have 49.85% of original data left, yielding a size of 73606.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.85% of original data left, yielding a size of 73606.\n",
      "We remove samples when S1 is not available. 2359 samples (3.20%) are removed. We have 48.26% of original data left, yielding a size of 71247.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 17\n",
      "We remove in-the-money samples. 74639 samples (50.28%) are removed. We have 49.72% of original data left, yielding a size of 73813.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.72% of original data left, yielding a size of 73813.\n",
      "We remove samples when S1 is not available. 2266 samples (3.07%) are removed. We have 48.20% of original data left, yielding a size of 71547.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 18\n",
      "We remove in-the-money samples. 73432 samples (50.13%) are removed. We have 49.87% of original data left, yielding a size of 73050.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.87% of original data left, yielding a size of 73050.\n",
      "We remove samples when S1 is not available. 2086 samples (2.86%) are removed. We have 48.45% of original data left, yielding a size of 70964.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 19\n",
      "We remove in-the-money samples. 73303 samples (50.37%) are removed. We have 49.63% of original data left, yielding a size of 72225.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.63% of original data left, yielding a size of 72225.\n",
      "We remove samples when S1 is not available. 2075 samples (2.87%) are removed. We have 48.20% of original data left, yielding a size of 70150.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We remove in-the-money samples. 74724 samples (50.27%) are removed. We have 49.73% of original data left, yielding a size of 73928.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.73% of original data left, yielding a size of 73928.\n",
      "We remove samples when S1 is not available. 2158 samples (2.92%) are removed. We have 48.28% of original data left, yielding a size of 71770.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run setup.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%run Load_Clean_aux.py normal\n",
    "\n",
    "seed = 666\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURE_SET == 'normal_feature':\n",
    "    ori_fea = ['M0', 'tau0_implvol0']\n",
    "    sub_res = res_dir + 'Network/Normal_Feature/'\n",
    "\n",
    "if FEATURE_SET == 'delta_vega':\n",
    "    ori_fea = ['delta_bs', '1_over_sqrt_tau', 'vega_n']\n",
    "    sub_res = res_dir + 'Network/Delta_Vega/'\n",
    "    \n",
    "if VIX:\n",
    "    ori_fea += ['fake_vix']\n",
    "\n",
    "    \n",
    "os.makedirs(sub_res, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Weiguan\\\\Dropbox\\\\Research\\\\DeepHedging\\\\Debug_0404\\\\BlackScholes/Result/CONFIG=4/FREQ=2D_HALFMONEY=otm_MINM=0.8_MAXM=1.5_Permute=False_VIX=False/Network/Delta_Vega/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    'nodes_per_layer': (30, 30),\n",
    "    'reg_alpha': 1e-3,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 500, #1000\n",
    "    'outact': 'linear'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Weiguan\\\\Dropbox\\\\Research\\\\DeepHedging\\\\Debug_0404\\\\BlackScholes/Result/CONFIG=4/FREQ=2D_HALFMONEY=otm_MINM=0.8_MAXM=1.5_Permute=False_VIX=False/Network/Delta_Vega/setup.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Note here, we use the same directory structure for the permuted and non-permuted data. \n",
    "For the non-permuted data:\n",
    "    The network is only trained once. so the ckp and the history are from that training.\n",
    "    Each of the pnls is for each different monte carlo, but they come from the same network.\n",
    "    \n",
    "For the permuted data:\n",
    "    The network is trained for the number of permutations. \n",
    "    Each of the pnls is for each permuations, and they comes from each trained network.\n",
    "\"\"\"\n",
    "\n",
    "sub_res_dirs = {\n",
    "    'ckp': sub_res + 'ckp/',\n",
    "    'history': sub_res + 'history/',\n",
    "    'pnl': sub_res + 'pnl/',\n",
    "    'plot': sub_res + 'plot/'\n",
    "}\n",
    "for key, value in sub_res_dirs.items():\n",
    "    os.makedirs(value, exist_ok=True)\n",
    "shutil.copy('setup.py', sub_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Weiguan\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Weiguan\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 230574 samples, validate on 82249 samples\n",
      "Epoch 1/500\n",
      "230574/230574 [==============================] - 7s 32us/step - loss: 0.1782 - mean_squared_error: 0.1460 - val_loss: 0.0508 - val_mean_squared_error: 0.0222\n",
      "Epoch 2/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0310 - mean_squared_error: 0.0059 - val_loss: 0.0297 - val_mean_squared_error: 0.0081\n",
      "Epoch 3/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0234 - mean_squared_error: 0.0048 - val_loss: 0.0223 - val_mean_squared_error: 0.0063\n",
      "Epoch 4/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0189 - mean_squared_error: 0.0047 - val_loss: 0.0193 - val_mean_squared_error: 0.0068\n",
      "Epoch 5/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0158 - mean_squared_error: 0.0046 - val_loss: 0.0171 - val_mean_squared_error: 0.0071\n",
      "Epoch 6/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0137 - mean_squared_error: 0.0046 - val_loss: 0.0160 - val_mean_squared_error: 0.0077\n",
      "Epoch 7/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0121 - mean_squared_error: 0.0046 - val_loss: 0.0134 - val_mean_squared_error: 0.0065\n",
      "Epoch 8/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0109 - mean_squared_error: 0.0046 - val_loss: 0.0126 - val_mean_squared_error: 0.0068\n",
      "Epoch 9/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0100 - mean_squared_error: 0.0046 - val_loss: 0.0114 - val_mean_squared_error: 0.0063\n",
      "Epoch 10/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0093 - mean_squared_error: 0.0046 - val_loss: 0.0118 - val_mean_squared_error: 0.0074\n",
      "Epoch 11/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0087 - mean_squared_error: 0.0046 - val_loss: 0.0105 - val_mean_squared_error: 0.0065\n",
      "Epoch 12/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0083 - mean_squared_error: 0.0045 - val_loss: 0.0108 - val_mean_squared_error: 0.0073\n",
      "Epoch 13/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0079 - mean_squared_error: 0.0045 - val_loss: 0.0103 - val_mean_squared_error: 0.0071\n",
      "Epoch 14/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0076 - mean_squared_error: 0.0046 - val_loss: 0.0085 - val_mean_squared_error: 0.0056\n",
      "Epoch 15/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0073 - mean_squared_error: 0.0045 - val_loss: 0.0094 - val_mean_squared_error: 0.0067\n",
      "Epoch 16/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0071 - mean_squared_error: 0.0045 - val_loss: 0.0080 - val_mean_squared_error: 0.0055\n",
      "Epoch 17/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0070 - mean_squared_error: 0.0045 - val_loss: 0.0084 - val_mean_squared_error: 0.0061\n",
      "Epoch 18/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0068 - mean_squared_error: 0.0045 - val_loss: 0.0088 - val_mean_squared_error: 0.0066\n",
      "Epoch 19/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0067 - mean_squared_error: 0.0045 - val_loss: 0.0082 - val_mean_squared_error: 0.0061\n",
      "Epoch 20/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0065 - mean_squared_error: 0.0045 - val_loss: 0.0089 - val_mean_squared_error: 0.0069\n",
      "Epoch 21/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0065 - mean_squared_error: 0.0045 - val_loss: 0.0082 - val_mean_squared_error: 0.0063\n",
      "Epoch 22/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0064 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0058\n",
      "Epoch 23/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0063 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0056\n",
      "Epoch 24/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0062 - mean_squared_error: 0.0045 - val_loss: 0.0088 - val_mean_squared_error: 0.0072\n",
      "Epoch 25/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0062 - mean_squared_error: 0.0045 - val_loss: 0.0100 - val_mean_squared_error: 0.0084\n",
      "Epoch 26/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0061 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0059\n",
      "Epoch 27/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0061 - mean_squared_error: 0.0045 - val_loss: 0.0075 - val_mean_squared_error: 0.0060\n",
      "Epoch 28/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0060 - mean_squared_error: 0.0045 - val_loss: 0.0082 - val_mean_squared_error: 0.0067\n",
      "Epoch 29/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0060 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0051\n",
      "Epoch 30/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0059 - mean_squared_error: 0.0045 - val_loss: 0.0085 - val_mean_squared_error: 0.0072\n",
      "Epoch 31/500\n",
      "230574/230574 [==============================] - 7s 29us/step - loss: 0.0059 - mean_squared_error: 0.0045 - val_loss: 0.0079 - val_mean_squared_error: 0.0066\n",
      "Epoch 32/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0059 - mean_squared_error: 0.0045 - val_loss: 0.0088 - val_mean_squared_error: 0.0075\n",
      "Epoch 33/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0058 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0058\n",
      "Epoch 34/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0058 - mean_squared_error: 0.0045 - val_loss: 0.0075 - val_mean_squared_error: 0.0062\n",
      "Epoch 35/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0058 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0054\n",
      "Epoch 36/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0058 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0060\n",
      "Epoch 37/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0057 - mean_squared_error: 0.0046 - val_loss: 0.0073 - val_mean_squared_error: 0.0061\n",
      "Epoch 38/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0057 - mean_squared_error: 0.0045 - val_loss: 0.0077 - val_mean_squared_error: 0.0066\n",
      "Epoch 39/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0057 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0063\n",
      "Epoch 40/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0057 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0054\n",
      "Epoch 41/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0056 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0060\n",
      "Epoch 42/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0056 - mean_squared_error: 0.0045 - val_loss: 0.0085 - val_mean_squared_error: 0.0074\n",
      "Epoch 43/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0056 - mean_squared_error: 0.0045 - val_loss: 0.0075 - val_mean_squared_error: 0.0065\n",
      "Epoch 44/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0056 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0062\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0056 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0060\n",
      "Epoch 46/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0055 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0058\n",
      "Epoch 47/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0055 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0060\n",
      "Epoch 48/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0055 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0059\n",
      "Epoch 49/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0055 - mean_squared_error: 0.0045 - val_loss: 0.0077 - val_mean_squared_error: 0.0068\n",
      "Epoch 50/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0055 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0058\n",
      "Epoch 51/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0055 - mean_squared_error: 0.0046 - val_loss: 0.0081 - val_mean_squared_error: 0.0071\n",
      "Epoch 52/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0055 - mean_squared_error: 0.0045 - val_loss: 0.0077 - val_mean_squared_error: 0.0068\n",
      "Epoch 53/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0055 - mean_squared_error: 0.0045 - val_loss: 0.0084 - val_mean_squared_error: 0.0074\n",
      "Epoch 54/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0054 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0058\n",
      "Epoch 55/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0054 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0058\n",
      "Epoch 56/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0054 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0053\n",
      "Epoch 57/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0054 - mean_squared_error: 0.0045 - val_loss: 0.0081 - val_mean_squared_error: 0.0073\n",
      "Epoch 58/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0054 - mean_squared_error: 0.0045 - val_loss: 0.0089 - val_mean_squared_error: 0.0080\n",
      "Epoch 59/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0054 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0060\n",
      "Epoch 60/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0054 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0061\n",
      "Epoch 61/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0054 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0068\n",
      "Epoch 62/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0053\n",
      "Epoch 63/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0064\n",
      "Epoch 64/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0061\n",
      "Epoch 65/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0075 - val_mean_squared_error: 0.0068\n",
      "Epoch 66/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0062\n",
      "Epoch 67/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0059\n",
      "Epoch 68/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0081 - val_mean_squared_error: 0.0074\n",
      "Epoch 69/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0059\n",
      "Epoch 70/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0063\n",
      "Epoch 71/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0051\n",
      "Epoch 72/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0064\n",
      "Epoch 73/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0053 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0059\n",
      "Epoch 74/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0062\n",
      "Epoch 75/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0073 - val_mean_squared_error: 0.0066\n",
      "Epoch 76/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0059\n",
      "Epoch 77/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0052 - mean_squared_error: 0.0046 - val_loss: 0.0061 - val_mean_squared_error: 0.0054\n",
      "Epoch 78/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0046 - val_loss: 0.0082 - val_mean_squared_error: 0.0075\n",
      "Epoch 79/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0046 - val_loss: 0.0067 - val_mean_squared_error: 0.0060\n",
      "Epoch 80/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0061\n",
      "Epoch 81/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0062\n",
      "Epoch 82/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0080 - val_mean_squared_error: 0.0074\n",
      "Epoch 83/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0065\n",
      "Epoch 84/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0062\n",
      "Epoch 85/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0065\n",
      "Epoch 86/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0054\n",
      "Epoch 87/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0050\n",
      "Epoch 88/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0056\n",
      "Epoch 89/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0059\n",
      "Epoch 90/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0058\n",
      "Epoch 91/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0057\n",
      "Epoch 92/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0052 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0070\n",
      "Epoch 94/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0078 - val_mean_squared_error: 0.0072\n",
      "Epoch 95/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0064\n",
      "Epoch 96/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0052\n",
      "Epoch 97/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0063\n",
      "Epoch 98/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0064\n",
      "Epoch 99/500\n",
      "230574/230574 [==============================] - 6s 26us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0082 - val_mean_squared_error: 0.0076\n",
      "Epoch 100/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0059\n",
      "Epoch 101/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0060\n",
      "Epoch 102/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0060\n",
      "Epoch 103/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0060\n",
      "Epoch 104/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0065\n",
      "Epoch 105/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0057\n",
      "Epoch 106/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0055\n",
      "Epoch 107/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0054\n",
      "Epoch 108/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0061\n",
      "Epoch 109/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0062\n",
      "Epoch 110/500\n",
      "230574/230574 [==============================] - 7s 30us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0060\n",
      "Epoch 111/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0057\n",
      "Epoch 112/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0056\n",
      "Epoch 113/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0052\n",
      "Epoch 114/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0046 - val_loss: 0.0076 - val_mean_squared_error: 0.0071\n",
      "Epoch 115/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0078 - val_mean_squared_error: 0.0072\n",
      "Epoch 116/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0063\n",
      "Epoch 117/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0061\n",
      "Epoch 118/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0051\n",
      "Epoch 119/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0058\n",
      "Epoch 120/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0059\n",
      "Epoch 121/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0061\n",
      "Epoch 122/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0059\n",
      "Epoch 123/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0065\n",
      "Epoch 124/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0046 - val_loss: 0.0065 - val_mean_squared_error: 0.0060\n",
      "Epoch 125/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0053\n",
      "Epoch 126/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0061\n",
      "Epoch 127/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0063\n",
      "Epoch 128/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0054\n",
      "Epoch 129/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0051 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0057\n",
      "Epoch 130/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0060\n",
      "Epoch 131/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0061\n",
      "Epoch 132/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0077 - val_mean_squared_error: 0.0072\n",
      "Epoch 133/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0073 - val_mean_squared_error: 0.0069\n",
      "Epoch 134/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0067\n",
      "Epoch 135/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0053\n",
      "Epoch 136/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0066\n",
      "Epoch 137/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0059\n",
      "Epoch 138/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0053\n",
      "Epoch 139/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0062\n",
      "Epoch 140/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0055\n",
      "Epoch 142/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0079 - val_mean_squared_error: 0.0074\n",
      "Epoch 143/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0055\n",
      "Epoch 144/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0052\n",
      "Epoch 145/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0058\n",
      "Epoch 146/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0054\n",
      "Epoch 147/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 148/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0064\n",
      "Epoch 149/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 150/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0060\n",
      "Epoch 151/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0056\n",
      "Epoch 152/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0056\n",
      "Epoch 153/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0055\n",
      "Epoch 154/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0075 - val_mean_squared_error: 0.0071\n",
      "Epoch 155/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 156/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0058\n",
      "Epoch 157/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0053\n",
      "Epoch 158/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0071\n",
      "Epoch 159/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0065\n",
      "Epoch 160/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0075 - val_mean_squared_error: 0.0071\n",
      "Epoch 161/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0058\n",
      "Epoch 162/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0062\n",
      "Epoch 163/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0061\n",
      "Epoch 164/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0058\n",
      "Epoch 165/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0052 - val_mean_squared_error: 0.0048\n",
      "Epoch 166/500\n",
      "230574/230574 [==============================] - 6s 26us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0065\n",
      "Epoch 167/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0079 - val_mean_squared_error: 0.0075\n",
      "Epoch 168/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0056\n",
      "Epoch 169/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0065\n",
      "Epoch 170/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 171/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0056\n",
      "Epoch 172/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 173/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0056\n",
      "Epoch 174/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0059\n",
      "Epoch 175/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0053 - val_mean_squared_error: 0.0048\n",
      "Epoch 176/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0063\n",
      "Epoch 177/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0066\n",
      "Epoch 178/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0065\n",
      "Epoch 179/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0058\n",
      "Epoch 180/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0056\n",
      "Epoch 181/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0068\n",
      "Epoch 182/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0068\n",
      "Epoch 183/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0079 - val_mean_squared_error: 0.0074\n",
      "Epoch 184/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0050\n",
      "Epoch 185/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0061\n",
      "Epoch 186/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0055\n",
      "Epoch 187/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0050 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0068\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0063\n",
      "Epoch 189/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0060\n",
      "Epoch 190/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0064\n",
      "Epoch 191/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0061\n",
      "Epoch 192/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0051\n",
      "Epoch 193/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0067\n",
      "Epoch 194/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0068\n",
      "Epoch 195/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0060\n",
      "Epoch 196/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 197/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0067\n",
      "Epoch 198/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 199/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0064\n",
      "Epoch 200/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0060\n",
      "Epoch 201/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0051\n",
      "Epoch 202/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 203/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0056\n",
      "Epoch 204/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0051\n",
      "Epoch 205/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0068\n",
      "Epoch 206/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0066\n",
      "Epoch 207/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 208/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0050\n",
      "Epoch 209/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0073 - val_mean_squared_error: 0.0069\n",
      "Epoch 210/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0067\n",
      "Epoch 211/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0062\n",
      "Epoch 212/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0061\n",
      "Epoch 213/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0062\n",
      "Epoch 214/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0060\n",
      "Epoch 215/500\n",
      "230574/230574 [==============================] - 5s 21us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0070\n",
      "Epoch 216/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 217/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 218/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0061\n",
      "Epoch 219/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0067\n",
      "Epoch 220/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0061\n",
      "Epoch 221/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0055\n",
      "Epoch 222/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0053\n",
      "Epoch 223/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0058\n",
      "Epoch 224/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0052\n",
      "Epoch 225/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0067\n",
      "Epoch 226/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0053\n",
      "Epoch 227/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0062\n",
      "Epoch 228/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0053\n",
      "Epoch 229/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0055\n",
      "Epoch 230/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 231/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0086 - val_mean_squared_error: 0.0082\n",
      "Epoch 232/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0077 - val_mean_squared_error: 0.0074\n",
      "Epoch 233/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0077 - val_mean_squared_error: 0.0073\n",
      "Epoch 234/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0052\n",
      "Epoch 235/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0058\n",
      "Epoch 237/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0054\n",
      "Epoch 238/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0063\n",
      "Epoch 239/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0060\n",
      "Epoch 240/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 241/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0065\n",
      "Epoch 242/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0061\n",
      "Epoch 243/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0055\n",
      "Epoch 244/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 245/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 246/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0064\n",
      "Epoch 247/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0073 - val_mean_squared_error: 0.0069\n",
      "Epoch 248/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 249/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0060\n",
      "Epoch 250/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0066\n",
      "Epoch 251/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 252/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0075 - val_mean_squared_error: 0.0071\n",
      "Epoch 253/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 254/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0067\n",
      "Epoch 255/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0065\n",
      "Epoch 256/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0060\n",
      "Epoch 257/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 258/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 259/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0061\n",
      "Epoch 260/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 261/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 262/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 263/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 264/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0052\n",
      "Epoch 265/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 266/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 267/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0072\n",
      "Epoch 268/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 269/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0053\n",
      "Epoch 270/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 271/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0063\n",
      "Epoch 272/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 273/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 274/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0050\n",
      "Epoch 275/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 276/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 277/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0058\n",
      "Epoch 278/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0051\n",
      "Epoch 279/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 280/500\n",
      "230574/230574 [==============================] - 5s 21us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 281/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 282/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0079 - val_mean_squared_error: 0.0075\n",
      "Epoch 284/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0073 - val_mean_squared_error: 0.0070\n",
      "Epoch 285/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 286/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0072\n",
      "Epoch 287/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 288/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 289/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0073 - val_mean_squared_error: 0.0069\n",
      "Epoch 290/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 291/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 292/500\n",
      "230574/230574 [==============================] - 7s 30us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 293/500\n",
      "230574/230574 [==============================] - 7s 30us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 294/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0062\n",
      "Epoch 295/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0054\n",
      "Epoch 296/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 297/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0053\n",
      "Epoch 298/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0073\n",
      "Epoch 299/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0065\n",
      "Epoch 300/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0064\n",
      "Epoch 301/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 302/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 303/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 304/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0055\n",
      "Epoch 305/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0050\n",
      "Epoch 306/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 307/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 308/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 309/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0053 - val_mean_squared_error: 0.0050\n",
      "Epoch 310/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0067\n",
      "Epoch 311/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 312/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0062\n",
      "Epoch 313/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0063\n",
      "Epoch 314/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0069\n",
      "Epoch 315/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 316/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 317/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 318/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 319/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 320/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 321/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0059\n",
      "Epoch 322/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0057\n",
      "Epoch 323/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0054\n",
      "Epoch 324/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 325/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 326/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0051\n",
      "Epoch 327/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 328/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0062\n",
      "Epoch 329/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0073 - val_mean_squared_error: 0.0070\n",
      "Epoch 330/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/500\n",
      "230574/230574 [==============================] - 6s 27us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 332/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 333/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 334/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 335/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0052\n",
      "Epoch 336/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0055\n",
      "Epoch 337/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0070\n",
      "Epoch 338/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 339/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 340/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 341/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 342/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 343/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 344/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 345/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 346/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 347/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 348/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 349/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 350/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 351/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0071\n",
      "Epoch 352/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 353/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 354/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0073\n",
      "Epoch 355/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0079 - val_mean_squared_error: 0.0076\n",
      "Epoch 356/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 357/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0053\n",
      "Epoch 358/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0049 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 359/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 360/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 361/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 362/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0063\n",
      "Epoch 363/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0061\n",
      "Epoch 364/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 365/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0065\n",
      "Epoch 366/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 367/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 368/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 369/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 370/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 371/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0053\n",
      "Epoch 372/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 373/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 374/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0071\n",
      "Epoch 375/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0051\n",
      "Epoch 376/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 377/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 379/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 380/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 381/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0073\n",
      "Epoch 382/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0075 - val_mean_squared_error: 0.0072\n",
      "Epoch 383/500\n",
      "230574/230574 [==============================] - 5s 21us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 384/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 385/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 386/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 387/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 388/500\n",
      "230574/230574 [==============================] - 6s 26us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 389/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 390/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 391/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0053 - val_mean_squared_error: 0.0050\n",
      "Epoch 392/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 393/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 394/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0054\n",
      "Epoch 395/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0078 - val_mean_squared_error: 0.0075\n",
      "Epoch 396/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 397/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 398/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 399/500\n",
      "230574/230574 [==============================] - 5s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 400/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 401/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 402/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 403/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 404/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0060\n",
      "Epoch 405/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0053 - val_mean_squared_error: 0.0050\n",
      "Epoch 406/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0054\n",
      "Epoch 407/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 408/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 409/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0067\n",
      "Epoch 410/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 411/500\n",
      "230574/230574 [==============================] - 6s 26us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0071\n",
      "Epoch 412/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0067\n",
      "Epoch 413/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 414/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 415/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 416/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 417/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0064\n",
      "Epoch 418/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 419/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 420/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 421/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 422/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0061\n",
      "Epoch 423/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 424/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 425/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0062\n",
      "Epoch 427/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0067\n",
      "Epoch 428/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 429/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 430/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 431/500\n",
      "230574/230574 [==============================] - 5s 21us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 432/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 433/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 434/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 435/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0052 - val_mean_squared_error: 0.0049\n",
      "Epoch 436/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 437/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 438/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0069 - val_mean_squared_error: 0.0066\n",
      "Epoch 439/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0067\n",
      "Epoch 440/500\n",
      "230574/230574 [==============================] - 5s 23us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 441/500\n",
      "230574/230574 [==============================] - 7s 30us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0074 - val_mean_squared_error: 0.0072\n",
      "Epoch 442/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 443/500\n",
      "230574/230574 [==============================] - 7s 29us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 444/500\n",
      "230574/230574 [==============================] - 6s 27us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 445/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0052\n",
      "Epoch 446/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 447/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0068\n",
      "Epoch 448/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 449/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 450/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0056\n",
      "Epoch 451/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 452/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0053\n",
      "Epoch 453/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0061\n",
      "Epoch 454/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 455/500\n",
      "230574/230574 [==============================] - 6s 28us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0054\n",
      "Epoch 456/500\n",
      "230574/230574 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0063\n",
      "Epoch 457/500\n",
      "230574/230574 [==============================] - 5s 21us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 458/500\n",
      "230574/230574 [==============================] - 5s 22us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0076 - val_mean_squared_error: 0.0073\n",
      "Epoch 459/500\n",
      "230574/230574 [==============================] - 5s 20us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 460/500\n",
      "230574/230574 [==============================] - 5s 20us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0051\n",
      "Epoch 461/500\n",
      "230574/230574 [==============================] - 5s 21us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0053\n",
      "Epoch 462/500\n",
      "230574/230574 [==============================] - 5s 20us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0066 - val_mean_squared_error: 0.0063\n",
      "Epoch 463/500\n",
      "230574/230574 [==============================] - 5s 20us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0078 - val_mean_squared_error: 0.0075\n",
      "Epoch 464/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0055 - val_mean_squared_error: 0.0052\n",
      "Epoch 465/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0070 - val_mean_squared_error: 0.0067\n",
      "Epoch 466/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 467/500\n",
      "230574/230574 [==============================] - 5s 20us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0051\n",
      "Epoch 468/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 469/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0058\n",
      "Epoch 470/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0072 - val_mean_squared_error: 0.0069\n",
      "Epoch 471/500\n",
      "230574/230574 [==============================] - 5s 20us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0082 - val_mean_squared_error: 0.0079\n",
      "Epoch 472/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 473/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230574/230574 [==============================] - 5s 20us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0049 - val_mean_squared_error: 0.0046\n",
      "Epoch 474/500\n",
      "230574/230574 [==============================] - 5s 21us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 475/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 476/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0051\n",
      "Epoch 477/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0053\n",
      "Epoch 478/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n",
      "Epoch 479/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0061\n",
      "Epoch 480/500\n",
      "230574/230574 [==============================] - 5s 21us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 481/500\n",
      "230574/230574 [==============================] - 6s 25us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0060 - val_mean_squared_error: 0.0057\n",
      "Epoch 482/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 483/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0053 - val_mean_squared_error: 0.0050\n",
      "Epoch 484/500\n",
      "230574/230574 [==============================] - 4s 19us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0063\n",
      "Epoch 485/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0073 - val_mean_squared_error: 0.0070\n",
      "Epoch 486/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0064\n",
      "Epoch 487/500\n",
      "230574/230574 [==============================] - 4s 17us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0064 - val_mean_squared_error: 0.0061\n",
      "Epoch 488/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0056 - val_mean_squared_error: 0.0053\n",
      "Epoch 489/500\n",
      "230574/230574 [==============================] - 4s 17us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 490/500\n",
      "230574/230574 [==============================] - 4s 17us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0058 - val_mean_squared_error: 0.0055\n",
      "Epoch 491/500\n",
      "230574/230574 [==============================] - 4s 17us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0051 - val_mean_squared_error: 0.0048\n",
      "Epoch 492/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0065 - val_mean_squared_error: 0.0062\n",
      "Epoch 493/500\n",
      "230574/230574 [==============================] - 4s 17us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0057 - val_mean_squared_error: 0.0054\n",
      "Epoch 494/500\n",
      "230574/230574 [==============================] - 4s 17us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0063 - val_mean_squared_error: 0.0060\n",
      "Epoch 495/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0061 - val_mean_squared_error: 0.0059\n",
      "Epoch 496/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0071 - val_mean_squared_error: 0.0068\n",
      "Epoch 497/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0078 - val_mean_squared_error: 0.0075\n",
      "Epoch 498/500\n",
      "230574/230574 [==============================] - 4s 17us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0062 - val_mean_squared_error: 0.0059\n",
      "Epoch 499/500\n",
      "230574/230574 [==============================] - 4s 17us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0067 - val_mean_squared_error: 0.0065\n",
      "Epoch 500/500\n",
      "230574/230574 [==============================] - 4s 18us/step - loss: 0.0048 - mean_squared_error: 0.0045 - val_loss: 0.0068 - val_mean_squared_error: 0.0065\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAD8CAYAAABNcdMMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8VNX5x/HPyU7Yw6YQVlkUCGtAQBYRZXHBFYUqULWutbZWbfVntS6te7VFbYW641otKi1YFQFZRAVk37cgYQ1bEhKyn98fM/dmZjJJRpg4A37frxcvMnfuvXNmcufkuc99zrnGWouIiIiIiIRHTKQbICIiIiJyMlGALSIiIiISRgqwRURERETCSAG2iIiIiEgYKcAWEREREQkjBdgiIiIiImEUUoBtjBlpjNlgjNlsjLknyPOJxpj3vM9/Y4xp413e1xiz3PtvhTHm0lD3KSIiIiJyIjLVzYNtjIkFNgLnAZnAYmCctXatzzq3At2stTcbY8YCl1prrzLGJANF1toSY8ypwAqgOWCr26eIiIiIyIkolAx2X2CztXartbYIeBe4OGCdi4HXvT9/AAwzxhhrbb61tsS7PAlPYB3qPkVERERETjhxIazTAtjh8zgTOLOydbzZ6mygEbDfGHMm8ArQGhjvfT6UfQJgjLkRuBGgdu3avU8//fQQmiwiEl5bs/IAaNek9jFtv3Tp0v3W2ibhbFM0Up8tIpF0vH2143j77FACbBNkWWBdSaXrWGu/AboYY84AXjfGfBLiPvFuPwWYApCenm6XLFkSQpNFRMLrqsmLAHjvpv7HtL0xZns42xOt1GeLSCQdb1/tON4+O5QSkUygpc/jVGBXZesYY+KA+sBB3xWsteuAPKBriPsUERERETnhhJLBXgx0MMa0BXYCY4GfBawzHZgILAKuAGZba613mx3espDWQCcgAzgcwj5FRKLGr87pEOkmiIhINaKlr642wPYGx7cBnwKxwCvW2jXGmIeBJdba6cDLwFRjzGY8meux3s0HAvcYY4qBMuBWa+1+gGD7DPN7ExEJm4EdGke6CSIiUo1o6atDyWBjrZ0JzAxY9oDPzwXAmCDbTQWmhrrPY1FcXExmZiYFBQXHuys5ASUlJZGamkp8fHykmyInuTW7sgHo0rx+hFtyYlOf/dOmPltqWrT01SEF2NEsMzOTunXr0qZNG4wJNnZSTlbWWg4cOEBmZiZt27aNdHPkJPfwfzzT9B/vwJmfOvXZP13qs+XHEC199Ql/q/SCggIaNWqkjvonyBhDo0aNlAkTOYGoz/7pUp8tPyUnfIANqKP+CdPvXuTEo+/tT5d+9/JTcVIE2CIiIiIi0UIBdhgYY7jzzjvdx08//TQPPvhgldvMnTuXr776Kuxtee2117jtttuqXccYwxdffOEu+/DDDzHG8MEHHwDw3//+l549e9K9e3c6d+7M5MmTAXjwwQdp0aIFPXr0cP8dPnw47O9DRKSmqM9Wny1S0074QY7RIDExkWnTpnHvvffSuHFo08PMnTuXOnXqMGDAgLC1o6SkJOR109LSeOeddxg2bBgA7777Lt27dwc8o/xvvPFGvv32W1JTUyksLCQjI8Pd9o477uCuu+4KW7tFTgS/G9kp0k2QMFGfLXLyipa+WhnsMIiLi+PGG2/k2WefrfBcVlYWl19+OX369KFPnz4sXLiQjIwMXnzxRZ599ll69OjBl19+Sbt27bDWcvjwYWJiYpg3bx4AgwYNYvPmzRw8eJBLLrmEbt260a9fP1auXAl4shM33ngjw4cPZ8KECX6vPWPGDPr378/+/fsrtGvQoEF8++23FBcXc+TIETZv3kyPHj0AyM3NpaSkhEaNGgGeP0adOkXHASsSKb1bp9C7dUqkmyFhoD5b5OQVLX31SZXBfug/a1i7Kyes++zcvB5/vKhLtev98pe/pFu3bvzud7/zW/7rX/+aO+64g4EDB/L9998zYsQI1q1bx80330ydOnXcrELHjh1Zu3Yt27Zto3fv3syfP58zzzyTzMxM2rdvz69+9St69uzJRx99xOzZs5kwYQLLly8HYOnSpSxYsIBatWrx2muvAZ7Lh8888wwzZ86kYcOGFdprjOHcc8/l008/JTs7m9GjR7Nt2zYAUlJSGD16NK1bt2bYsGFceOGFjBs3jpgYz/nYs88+y5tvvglAw4YNmTNnzrF9uCInkKXbDwJERcd9slCfrT5bJNyipa8+qQLsSKpXrx4TJkxg0qRJ1KpVy10+a9Ys1q5d6z7OyckhNze3wvaDBg1i3rx5bNu2jXvvvZd//vOfDBkyhD59+gCwYMEC/v3vfwNwzjnncODAAbKzPZOpjx492u8158yZw5IlS/jss8+oV69epW0eO3YskyZNIjs7m7/85S88+uij7nMvvfQSq1atYtasWTz99NN8/vnn7h8CXW6Un6In/7cBiPzcqhIe6rNFTk7R0lefVAF2KFmLmvSb3/yGXr16ce2117rLysrKWLRokV9nGsygQYN48cUX2bVrFw8//DBPPfUUc+fOZfDgwYBngv5AznRHtWvX9lverl07tm7dysaNG0lPT6/0Nfv27cvq1aupVasWHTt2rPB8WloaaWlpjB8/nrZt27qdtYhIOKjP9lCfLXLyUQ12GKWkpHDllVfy8ssvu8uGDx/O888/7z52LhHWrVvXLyty5pln8tVXXxETE0NSUhI9evRg8uTJDBo0CIDBgwfz1ltvAZ7BNo0bN64009G6dWumTZvGhAkTWLNmTZVtfuyxx/yyIABHjhxh7ty5fm1u3bp1CJ+AiMiJQ322iNQUBdhhduedd/oNUJk0aRJLliyhW7dudO7cmRdffBGAiy66iA8//JAePXowf/58EhMTadmyJf369QM82ZHc3FzS0tIAz8AYZz/33HMPr7/+epXt6NSpE2+99RZjxoxhy5Ytla43atQohg4d6rfMWsuTTz5Jp06d6NGjB3/84x/9MiHOQB/nn+9odRGRE4n6bBGpCSbYZaxolZ6ebpcsWeK3bN26dZxxxhkRapFEAx0D8mO4avIi4Njr+owxS621lV//Pwmpz5ZgdAxITTrevtpxvH32SVWDLSJSUx64qHOkmyAiItWIlr5aAbaISAi6NK8f6SaIiEg1oqWvVg22iEgIFmzaz4JNFW8AIiIi0SNa+mplsEVEQvDc7E0ADOwQ2q21RUTkxxctfbUy2CIiIiIiYaQAW0REREQkjBRgh0FsbCw9evSge/fu9OrVi6+++gqAjIwMunbtekz7PPvsswmc3ipQfn4+V199NWlpaXTt2pWBAwdy5MiRStf/+c9/zgcffBByG46n/b7OPvtsWrVq5Xdns0suuYQ6deoAnjun3X777XTt2pW0tDT69OnDtm3bAGjTpg1paWnu/K233377cbdHRH7a1GdXTX22yPFTDXYY1KpVy73b16effsq9997Ll19+WeOv+7e//Y1mzZqxatUqADZs2EB8fHyNv+6xaNCgAQsXLmTgwIEcPnyY3bt3u8+999577Nq1i5UrVxITE0NmZqbfrYTnzJlD48aqexWR8FCfXT312SLHRxnsMMvJyaFhw4YVlmdkZDBo0CB69erllzEBePLJJ0lLS6N79+7cc889ftuVlZUxceJE/vCHP1TY5+7du2nRooX7uFOnTiQmJgLwxhtv0K1bN7p378748ePddebNm8eAAQNo166dmxmx1nL33Xe72Yj33nuvwmuVlpZy991306dPH7p168bkyZPdNgwePJgePXrQtWtX5s+fH/RzGTt2LO+++y4A06ZN47LLLvN7H6eeeioxMZ7DMTU1NehnKBJJj16WxqOXpUW6GRJm6rPVZ8vJJVr66pMrg/2b34A3KxE2PXrAX/9a5SpHjx6lR48eFBQUsHv3bmbPnl1hnaZNm/L555+TlJTEpk2bGDduHEuWLOGTTz7ho48+4ptvviE5OZmDBw+625SUlHD11VfTtWtX7rvvvgr7vO666xg+fDgffPABw4YNY+LEiXTo0IE1a9bw5z//mYULF9K4cWO/fe7evZsFCxawfv16Ro8ezRVXXMG0adNYvnw5K1asYP/+/fTp04fBgwf7vdbLL79M/fr1Wbx4MYWFhZx11lkMHz6cadOmMWLECO677z5KS0vJz88P+hkNGzaMG264gdLSUt59912mTJnCI488AsCVV17JwIEDmT9/PsOGDeOaa66hZ8+e7rZDhw4lNjYWgIkTJ3LHHXdU+fsQqQmnNakT6SacfNRnq88WCbNo6atPrgA7QnwvNy5atIgJEyawevVqv3WKi4u57bbbWL58ObGxsWzcuBGAWbNmce2115KcnAxASkqKu81NN93ElVdeGbSjBujRowdbt27ls88+Y9asWfTp04dFixYxe/ZsrrjiCvcSne8+L7nkEmJiYujcuTN79+4FYMGCBYwbN47Y2FiaNWvGkCFDWLx4Md26dXO3++yzz1i5cqWbQcnOzmbTpk306dOH6667juLiYi655BJ69OgRtK2xsbEMHDiQ9957j6NHj9KmTRv3udTUVDZs2MDs2bOZPXs2w4YN4/3332fYsGGALjdKdJi11vN9Obdzswi3RI6X+mz12XLyipa++uQKsKvJWvwY+vfvz/79+8nKyvJb/uyzz9KsWTNWrFhBWVkZSUlJgOdSnzEm6L4GDBjAnDlzuPPOO0lKSuLDDz/koYceAuCll14iPT2dOnXqcNlll3HZZZcRExPDzJkziY+Pr3SfzuVI57V9/6+KtZbnnnuOESNGVHhu3rx5zJgxg/Hjx3P33XczYcKEoPsYO3Ysl156KQ8++GDQdo0aNYpRo0bRrFkzPvroI7ezFokG/5y/FYh8p31SUZ+tPlskzKKlr1YNdpitX7+e0tJSGjVq5Lc8OzvbrVmbOnUqpaWlAAwfPpxXXnnFvUzne2nw+uuv5/zzz2fMmDGUlJRw6aWXsnz5cpYvX056ejoLFy7k0KFDABQVFbF27Vpat27NsGHD+Ne//sWBAwcq7DOYwYMH895771FaWkpWVhbz5s2jb9++fuuMGDGCf/zjHxQXFwOwceNG8vLy2L59O02bNuWGG27g+uuv57vvvqv0dQYNGsS9997LuHHj/JZ/99137Nq1C/DUL65cuZLWrVtX2WYRkXBQn60+W6QmnFwZ7Ahx6vnAkzV4/fXX3fozx6233srll1/O+++/z9ChQ90R1yNHjnQ734SEBM4//3weffRRd7vf/va3ZGdnM378eN566y13UAnAli1buOWWW7DWUlZWxgUXXMDll1+OMYb77ruPIUOGEBsbS8+ePXnttdcqbf+ll17KokWL6N69O8YYnnzySU455RQyMjLcdX7xi1+QkZFBr169sNbSpEkTPvroI+bOnctTTz1FfHw8derU4Y033qj0dYwx3HXXXRWW79u3jxtuuIHCwkIA+vbty2233eY+71vP161btypfQ0SkOuqz1WeL1DQTyqUmY8xI4G9ALPCStfbxgOcTgTeA3sAB4CprbYYx5jzgcSABKALuttbO9m4zFzgVOOrdzXBr7b6q2pGenm4D5xldt24dZ5xxRrXvQU5eOgbkx3DV5EUAvHdT/2Pa3hiz1FqbHs42RTv12RKMjgGpScfbVzuOt8+uNoNtjIkFXgDOAzKBxcaY6dbatT6rXQ8csta2N8aMBZ4ArgL2AxdZa3cZY7oCnwItfLa72lpb9cz8IiIiIiInkFBKRPoCm621WwGMMe8CFwO+AfbFwIPenz8AnjfGGGvtMp911gBJxphEa23hcbdcRORH9OxVwWdbEBGR6BEtfXUoAXYLYIfP40zgzMrWsdaWGGOygUZ4MtiOy4FlAcH1q8aYUuDfwJ9sKPUqIiIR0LxBrUg3QUREqhEtfXUos4gEmzsoMBCuch1jTBc8ZSM3+Tx/tbU2DRjk/TeeIIwxNxpjlhhjlgROoyQi8mP5z4pd/GfFrkg3I+qpzxaRSIqWvjqUADsTaOnzOBUIbLm7jjEmDqgPHPQ+TgU+BCZYa7c4G1hrd3r/zwXexlOKUoG1doq1Nt1am96kSZNQ3pOISNi9+fV23vx6e6SbEfXUZ4tIJEVLXx1KgL0Y6GCMaWuMSQDGAtMD1pkOTPT+fAUw21prjTENgBnAvdbahc7Kxpg4Y0xj78/xwIXAakRERERETnDVBtjW2hLgNjwzgKwD/mWtXWOMedgYM9q72stAI2PMZuC3wD3e5bcB7YH7jTHLvf+aAonAp8aYlcByYCfwz3C+sR+TMYbx48srXEpKSmjSpAkXXnghANOnT+fxxx+vbHMAdu3axRVXXFGj7azKgw8+yNNPPx2x1xcR+bGozxaRmhbSjWastTOBmQHLHvD5uQAYE2S7PwF/qmS3vUNvZnSrXbs2q1ev5ujRo9SqVYvPP/+cFi3KZyMcPXo0o0ePrmIP0Lx5cz744IOabqqIyE+e+mwRqWm6VXqYjBo1ihkzZgDwzjvv+N1a9rXXXnPvcvXzn/+c22+/nQEDBtCuXTu3g87IyKBr167u+pdccgkXXXQRbdu25fnnn+eZZ56hZ8+e9OvXz72N7tlnn41zE4f9+/fTpk2bH7R9ZZYvX06/fv3o1q0bl156qXtr30mTJtG5c2e6devG2LFjAfjyyy/p0aMHPXr0oGfPnuTm5obj4xQRqVHqs9Vni9Skk+5W6c4dfHxd2O1Uxvdvw9GiUn7+6rcVnr+idypj0ltyMK+IW95c6vdcqHcCGjt2LA8//DAXXnghK1eu5LrrrmP+/PlB1929ezcLFixg/fr1jB49OuhlxtWrV7Ns2TIKCgpo3749TzzxBMuWLeOOO+7gjTfe4De/+U2V7Tme7SdMmMBzzz3HkCFDeOCBB3jooYf461//yuOPP862bdtITEzk8OHDADz99NO88MILnHXWWRw5coSkpKSQPi+RE80/rjlpLrpFFfXZx7+9+myRctHSVyuDHSbdunUjIyODd955h/PPP7/KdS+55BJiYmLo3Lkze/fuDbrO0KFDqVu3Lk2aNKF+/fpcdNFFAKSlpZGRkVFte451++zsbA4fPsyQIUMAmDhxIvPmzXPf49VXX82bb75JXJzn3Oyss87it7/9LZMmTeLw4cPucpGTTUrtBFJqJ0S6GRIm6rPVZ8vJKVr66pPum1VV9qJWQmyVz6fUTjiue9ePHj2au+66i7lz53LgwIFK10tMTHR/ruzeOr7rxMTEuI9jYmIoKSkBIC4ujrKyMgAKCgp+8PY/1IwZM5g3bx7Tp0/nkUceYc2aNdxzzz1ccMEFzJw5k379+jFr1ixOP/30Y9q/SDR7f4nnfltj0ltWs6b8EOqzQ9/+h1KfLT9F0dJXK4MdRtdddx0PPPAAaWlpP8rrtWnThqVLPZdHwzXYpn79+jRs2NC9VDp16lSGDBlCWVkZO3bsYOjQoTz55JMcPnyYI0eOsGXLFtLS0vj9739Peno669evD0s7RKLNB0sz+WBpZqSbIWGkPlt9tpx8oqWvPuky2JGUmprKr3/96x/t9e666y6uvPJKpk6dyjnnnBO2/b7++uvcfPPN5Ofn065dO1599VVKS0u55ppryM7OxlrLHXfcQYMGDbj//vuZM2cOsbGxdO7cmVGjRoWtHSIiNUl9tvpskZpiKrvcFY3S09OtMwLbsW7dOs4444wItUiigY4B+TE4g/GOtSTBGLPUWpsezjZFO/XZEoyOAalJx9tXO463z1aJiIiIiIhIGCnAFhEREREJo5OiBttaizEm0s2QCDiRSpzkxPbatX0j3YSThvrsny712VLToqWvPuEz2ElJSRw4cEBf2p8gay0HDhzQjRLkR1ErIZZaCbGRbsYJT332T5f6bPkxREtffcJnsFNTU8nMzCQrKyvSTZEISEpKIjU1NdLNkJ+AqYsyABjfv00km3HCU5/906Y+W2patPTVJ3yAHR8fT9u2bSPdDBE5yf135W4g8p32iU59tojUpGjpq0/4EhERERERkWiiAFtEREREJIwUYIuIiIiIhJECbBERERGRMDrhBzmKiPwYjve2uyIiUvOipa9WBltEREREJIwUYIuIhGDKvC1Mmbcl0s0QEZEqREtfrQBbRCQEX6zbxxfr9kW6GSIiUoVo6asVYIuIiIiIhJECbBERERGRMFKALSIiIiISRpqmT0QkBEnxsZFugoiIVCNa+moF2CIiIXj9ur6RboKIiFQjWvpqlYiIiIiIiISRAmwRkRBM+mITk77YFOlmiIhIFaKlrw4pwDbGjDTGbDDGbDbG3BPk+URjzHve578xxrTxLj/PGLPUGLPK+/85Ptv09i7fbIyZZIwx4XpTIiLhtnDzfhZu3h/pZoiISBWipa+uNsA2xsQCLwCjgM7AOGNM54DVrgcOWWvbA88CT3iX7wcustamAROBqT7b/AO4Eejg/TfyON6HiIiIiEhUCCWD3RfYbK3daq0tAt4FLg5Y52Lgde/PHwDDjDHGWrvMWrvLu3wNkOTNdp8K1LPWLrLWWuAN4JLjfjciIiIiIhEWSoDdAtjh8zjTuyzoOtbaEiAbaBSwzuXAMmttoXf9zGr2CYAx5kZjzBJjzJKsrKwQmisiIpGiPltEJLQAO1httP0h6xhjuuApG7npB+zTs9DaKdbadGttepMmTUJorohI+DVMTqBhckKkmxH11GeLSCRFS18dyjzYmUBLn8epwK5K1sk0xsQB9YGDAMaYVOBDYIK1dovP+qnV7FNEJGq8OL53pJsgIiLViJa+OpQM9mKggzGmrTEmARgLTA9YZzqeQYwAVwCzrbXWGNMAmAHca61d6Kxsrd0N5Bpj+nlnD5kAfHyc70VEREREJOKqDbC9NdW3AZ8C64B/WWvXGGMeNsaM9q72MtDIGLMZ+C3gTOV3G9AeuN8Ys9z7r6n3uVuAl4DNwBbgk3C9KRGRcHvif+t54n/rI90MERGpQrT01SHdKt1aOxOYGbDsAZ+fC4AxQbb7E/CnSva5BOj6QxorIhIp320/FOkmiIhINaKlr9adHEVEREREwkgBtoiIiIhIGCnAFhEREREJo5BqsEVEfupOrZ8U6SaIiEg1oqWvVoAtIhKCv47tGekmiIhINaKlr1aJiIiIiIhIGCnAFhEJwUP/WcND/1kT6WaIiEgVoqWvVomIiEgI1u7KiXQTRESkGtHSVyuDLSIiIiISRgqwRURERETCSAG2iIiIiEgYqQZbRCQE7ZrUjnQTRESkGtHSVyvAFhEJwWOXdYt0E0REpBrR0lerREREREREJIwUYIuIhODeaSu5d9rKSDdDRESqEC19tUpERERCsDUrL9JNEBGRakRLX60MtoiIiIhIGCnAFhEREREJIwXYIiIiIiJhpBpsEZEQdG5eL9JNEBGRakRLX60AW0QkBH+8qEukmyAiItWIlr5aJSIiIiIiImGkAFtEJAS/eXcZv3l3WaSbISIiVYiWvlolIiIiIdidXRDpJoiISDWipa9WBltEREREJIwUYIuIiIiIhJECbBERERGRMAopwDbGjDTGbDDGbDbG3BPk+URjzHve578xxrTxLm9kjJljjDlijHk+YJu53n0u9/5rGo43JCJSE3q1bkiv1g0j3QwREalCtPTV1Q5yNMbEAi8A5wGZwGJjzHRr7Vqf1a4HDllr2xtjxgJPAFcBBcD9QFfvv0BXW2uXHOd7EBGpcb8feXqkmyAiItWIlr46lAx2X2CztXartbYIeBe4OGCdi4HXvT9/AAwzxhhrbZ61dgGeQFtERERE5KQXSoDdAtjh8zjTuyzoOtbaEiAbaBTCvl/1lofcb4wxwVYwxtxojFlijFmSlZUVwi5FRMLv5qlLuXnq0kg3I+qpzxaRSIqWvjqUADtY4GuPYZ1AV1tr04BB3n/jg61krZ1irU231qY3adKk2saKiNSEQ/lFHMovinQzop76bBGJpGjpq0MJsDOBlj6PU4Fdla1jjIkD6gMHq9qptXan9/9c4G08pSgiIiIiIie0UALsxUAHY0xbY0wCMBaYHrDOdGCi9+crgNnW2koz2MaYOGNMY+/P8cCFwOof2ngRERERkWhT7Swi1toSY8xtwKdALPCKtXaNMeZhYIm1djrwMjDVGLMZT+Z6rLO9MSYDqAckGGMuAYYD24FPvcF1LDAL+GdY35mIiIiISARUG2ADWGtnAjMDlj3g83MBMKaSbdtUstveoTVRRCTyzmrfONJNEBGRakRLXx1SgC0i8lN3+7AOkW6CiIhUI1r6at0qXUREREQkjBRgi4iEYOIr3zLxlW8j3QwREalCtPTVKhEREQlBQXFppJsgIiLViJa+WhlsEREREZEwUoAtIiIiIhJGCrBFRERERMJINdgiIiEYdkbTSDdBRESqES19tQJsEZEQ3Dj4tEg3QUREqhEtfbVKREREREREwkgBtohICK6avIirJi+KdDNERKQK0dJXK8AWEREREQkjBdgiIiIiImGkAFtEREREJIwUYIuIiIiIhJGm6RMRCcGF3U6NdBNERKQa0dJXK8AWEQnB+P5tIt0EERGpRrT01SoREREJwdGiUo4WlUa6GSIiUoVo6asVYIuIhODnr37Lz1/9NtLNEBGRKkRLX60AW0REREQkjBRgi4iIiIiEkQJsEREREZEwUoAtIiIiIhJGmqZPRCQEV/ROjXQTRESkGtHSVyvAFhEJwZj0lpFugoiIVCNa+mqViIiIhOBgXhEH84oi3QwREalCtPTVymCLiITgljeXAvDeTf0j3BIREalMtPTVIWWwjTEjjTEbjDGbjTH3BHk+0Rjznvf5b4wxbbzLGxlj5hhjjhhjng/YprcxZpV3m0nGGBOONyQiIiIiEknVBtjGmFjgBWAU0BkYZ4zpHLDa9cAha2174FngCe/yAuB+4K4gu/4HcCPQwftv5LG8ARERERGRaBJKBrsvsNlau9VaWwS8C1wcsM7FwOvenz8AhhljjLU2z1q7AE+g7TLGnArUs9YustZa4A3gkuN5IyIiIiIi0SCUALsFsMPncaZ3WdB1rLUlQDbQqJp9ZlazTwCMMTcaY5YYY5ZkZWWF0FwREYkU9dkiIqENcgxWG22PYZ1jWt9aOwWYApCenl7VPkVEaswIEOc+AAAgAElEQVQ1/VpHugknBPXZIhJJ0dJXhxJgZwK+kwqmArsqWSfTGBMH1AcOVrNP35nAg+1TRCRqXNS9eaSbICIi1YiWvjqUEpHFQAdjTFtjTAIwFpgesM50YKL35yuA2d7a6qCstbuBXGNMP+/sIROAj39w60VEfiS7Dh9l1+GjkW6GiIhUIVr66moz2NbaEmPMbcCnQCzwirV2jTHmYWCJtXY68DIw1RizGU/meqyzvTEmA6gHJBhjLgGGW2vXArcArwG1gE+8/0REotId7y0HIj+3qoiIVC5a+uqQbjRjrZ0JzAxY9oDPzwXAmEq2bVPJ8iVA11AbKiIiIiJyItCt0kVEREREwkgBtoiIiIhIGCnAFhEREREJo5BqsEVEfupuGNQu0k0QEZFqREtfrQBbRCQE53ZuFukmiIhINaKlr1aJiIhICLZkHWFL1pFIN+OEU1BcyotfbqG4tCzSTRGRn4Bo6asVYIuIhOD/pq3i/6atinQzTjjPz97M45+s58NlOyPdFImwz9fu5ZUF2yLdDDnJRUtfrRIRERGpMVm5hQCUlVV6c98fzFrL7uwCmjeoFbZ9Ss274Y0lAFw3sG2EWyJS85TBFhGRGpNfXApArYTYsO1zyrytDHh8Nluj4DKw/HClYTzZEolWCrBFRKTGHC3yBNgxxoRtnzNX7wHgQF5R2PYpP54DeYWRboKchD5evpNBT84mWk7fFGCLiEiNKfBmsJ3/wyHnaHHY9lUVay07Dub/KK/1U7IvRwG2hN/qndnsOHg0aq6QKMAWEQnBr87pwK/O6RDpZpxwjjoBdkn4ZhE5nO/JXOcXhR6078spIGN/3g96nSnztjLoyTls3pf7g7aTqu3LLYjYay/acoBPVu2O2Osfi9Iyyx8+WsWKHYdr9HW+2rKfj5efGIORcwqK2bzPv0TswBFPv/Czvi2Pua9+beE2Nu0Nz/ddAbaISAgGdmjMwA6NI92ME45TIlLok8Hu8sD/uO61xRXWXbr9EA9OX4O1FTNQ7y3+notfWAjAYW8G+2hRSYX1MvbnBc2W9330C85+ei4AX23eT1EIAf+8TVkA7Dxc8wGhtZZnP9/IzsNHj2n75TsO0+aeGSzdfqjK9Y4WlXLxCwv57vuq16sJcTGeMqFIZrBfmr+VR/67NmKvfyzmb8riza+/58lP19fo6/zsn9/w63eX1+hrhMtVk7/m3Ge+9FvmlIx1bFbvmPrq/KISHvzPWsb985uwtFEBtohICNbsymbNruxIN+OE4wS7hT4BbV5RKbPX76uw7rgpX/PaVxkcKawYOP/+354MXklpGU78nVfoH0gXlZRx9tNzuf2dZZW2Z+2uHH720jc89sm6oM9ba90Av7jU878TGFbGWsuCTftDujSdV1jCt9sOVli+ad8R/vbFJn719nfV7iOYz9d66tIXbt5f5XrLvj/Eih2HeXRG8Pdfk+okeSYue3VhRkgnOD9EflFJSGVIuYUl7MouYPuBPPYfCR7oF5eW8dgn6zgYJTX+M70Z91Ypyce8j61ZR3jui00ndMnTws37+WLdXgDW7c4B8DsZd2r7V+08fEx99S7viXRhmMrZFGCLiITg4f+s5eH/nFiZr2jgBMsFxaUUl5Zx89Slla4b6w1k9x/xD2z+t7r8kn5uQXnwnR/whzC3wJPZnrOhYvDuyPZmv1dmBv8D/OjMdaT/aRbWWjdgPlpNKcrf527hmpe/4bM1e6pcD+DPM9dx5eRFFcpVnNeqrOyloLjUnTVl8pdb+GLdXvZkl2fWnZON5Gpma9nnnTaxab3EatsabqWllhgDG/bmsjs7tEx9flEJb3/zfdCrGr6ufXUxD4Xw/czzHo9DnppL+p9mBV1nweb9TP5yK3+cviakNtaUA0cKWb0z2/2dFRSHflLiOREt/8xeXrCNv3y+kX98uaXabau7KdTenALmVvEd+yFmr9/LhFe+rfb3C3D1S99w/etL/Jb5nrg7JSKvLsw4pr56l/fqUb1a8T9422AUYIuISI1xAuKC4lIy9ufxvyqC0MR4z5+kwMzizW+WZ3WzfJ4LLBHxDb4rb48nwA6WQS0oLuWf87dxIK+InIISSrxBb16QUhRfL3tvnnIwv/qMp/NHfEWmfz1tdUHNb/+1nHP+8iUFxaU89sl6rn99Cf0e+8J9Pt/bxsT46gJsT1DetG5StW0N1fxNWdWWpgAUlJTSplFtIPT6+cc/Wc//fbiKeZuqzsx/fzCfLfuqn7Yx8HULikspCfjsE2M9x+HuYyzXCbRmVzZ/n7vZb9m/Fu+gzT0zqsy6j5m8iAufW+Ae16EO7rXW0v6+T3jQ5wQh44DnhO5QCFn57Gpe5+Y3l/LzVxdXu14obnhjKfM2ZgW9ahUK5/Oz1roBdlVXkv7y2QbO8ZaKBVKALSIiJ4TSMls+yLG4jNJqslRJcZ7gcH9ueRAdGAhn+TwXGCzlFFT/B3/HoaNB9wuwNas8q7w3p8ANvKoL3J0Ckv251QcvzbyBbWBAGljuEmjeRk+AWVnZQl6QWvdAZWWWBZsPAJAYF4O11i+wt9YyZ8M+N1j3Za1l2neZ5BWWMH9TFi/MKQ8Yx7/8LZf/46sq219cWkZxqaVh7QSgfPBrMJ+s2s01L31DWZl167WPVPM7yC0o8Tv5qkxgIHf6/f/jmpf9a26LvJ/JoWpOmKy1TJm3pdrbcl/+j6948n8b/K6E/HXWRsD/eA7kHI87vcdsKMc3lH8vXl+03V2Wsd9TGhJKUHw4v+p1nCB9WRjq+J2rVofyPK/5/YF8NuypepChb7bbOY5yC0vc31tVAfZzszezdX9e0O+/E2DXDtOc/QqwRUSkRvhm57YfzOePH1d9yd3JYDuB0pHCEjr+4RO/dXxnoJj23U4GPzmH4tIyzvnLXPeysKHymmmnBrWwpGKA5xt87MkucP9Q51WTXXP+sFdW0+vLCZI+XLaTA77Z+OKqXyMu1vOedgVkVZ1gw2ljVZnAL9bvY95Gz8DNguJS7v94NR3u+8Tdx9Svt3Ptq4t5+5vv+ffSTL/ge0vWEX77rxXc/OZSbn3zO576dEOFWRyyjxZz34er3KsEuQXFLM446L4eQIoTYFeRwf50zR4WbN7P9oP5xHijlL98vqHSWWBKyyxHCkuqDFYdwX6XX2/1r4l32lZZMLp+Tw7vL9lBVm4hj85czyXPL6zyNZ3Sjj055ceu8c4LH0rm1tku1IyxMwjYGTpQWFLqluSEEqQfruLEYvuBPJK8V0mWZFQdYFtrya4iWD+YV+QGus7Vn8FPzWHEX+dVWNf3ePH9zP45bxulZeXZa8C98lSVzEMVa9F3eUuuCoL0DcdCAbaIiNQI3yzlvI1ZfBNkcB/AnPX7OJxfVF6D7Q2UfGuMHb4zUHx/MJ/vD+azJ7uArVl5LHGywj7x9fYDeczxGVDpBNjBMqi+wceenAL3j39VAba11s0YBgZ4i7YcqJApO5hXRFJ8DLkFJfz63eUs3X7Q+xpV/1GP80aagbOMOMGbE2AEK714+tMNvDBns98At4LiMt78+nugPLD4ePkuwBNo3/n+Cib71Os67Zu/aT8dT6kLwIfL/IPwlxds461vvuftbzz7ve3tZYx5cRE5BcXu593IG2D7ttNa65cFXu/NYL4wZzMzV3lKirZm5XH+pPlBPxsnu32ksKTSwH3n4aMs2nKg0tKU7QfyuGnqEnILit2rAYcqCQ7HTvmauz9Y6dbx51bxuit9SoF8S06cY72qbHFswODanKP+x2FOQTF/m7XJ7zU8+/QcC/HeUpfMQ0dxYs5QgvT7P17D32ZtCvrckKfmur8fZyBhWZll8pdb2H4gj4f+s8Y90Xx/aSbdH/4s6DSXe3MK6PXI5+7jQ3lFlFURGPuevPoG068s3Ma/luzwO1n1zWDvyy0ImtH+PshgT6fWPa+wtNoseigUYIuIhOB3Izvxu5GdIt2ME0pVZQDgKdPYl1vAta8t5rrXFpPvDeKcP3S+AevYPi0rLHP8KsisIaVlltyCYs5+ei7X+kwJuMObudqbU8h1ry32259vjeu+nAK3ROBIYSl7cwro9+gX7uwF7nsoLXP/gPuWKKzemc24f37NUwFTqx3OL6Zr8/qAZzCdU78dWJZRXFrGtO8y3aAj3pvBDgywDx/1tNEpHZkybytvfVNeGrAvp4Dn52zmqU83MGvdXoyB1Ia1KCgpdbPJUxdt5z8rdrknEtsPeD6jv3y+kfV7PO/X9yTDCftW7Mj2C3acqwJOEOsEfkcKSij0nggEKxF55vONDPvLl6zbnUNRSZmbGf9gaabfe80vKnWz49ZaHvh4Nd9sPeB3YhTsKkJZmeWsx2cz7p9fV3jO8fKCbXy6Zi8fLM10a/tLyyxjpyyqULdc4p1d5r8rd7nLAgO24tIyxk35mtE+2e3dPieMTvBcVcAbOGB1T04Bbe6ZwZfeqxAzVu7m2VkbGf38QrZmHeGDpZnc/s4yN2gvKi3j1reWMmOlZ5DwGafWC5pRzjyU7zf7zLrdOTw7ayOZh/L9stmB4wTmbMjihjeWMGfDPh77ZD2/eH0Jry7McGeocQZCnvvMvAoB639W7PJ7fDCviG0Hyq9QBA563OfzPc044H8lY19Ood/A6DNOrcvvRnaioLiUvn/+gqFPz2VxxkG/q1bBAmznxH7b/jxG/a1iFv2HUoAtIhKC3q1T6N06JdLNOKFUltWb0L814AkuVuzwZMG++/6wGyh9vfUA1lq/cpDmDWoB/n9oHcsDbsBRVFLG7/+9krQHPyOw7Nv3D+vs9fvcKdCc9oDn0vrTn210M5hHCouZuWo3e3IKeP2rDL/95ftknn2DdSf7viIzmy83ZjFlnicbfDC/yG+6tR0Hj/L9gXwenekfiL/+VQa//dcKpi3z3PjDCcicetyerRoA5bWruT5B5n0frvZ7j46VmdnUrxVPckIsBcWlNKvnqQd/8cst/OqdZRVqjq2Fi55b4P0MygNsJ8BZtTPb7z07wZtzouGUQeQWlLgBdUqyUyJSQk5BMbe8uZTnZnvquVfvzGZL1hFKyiymkiofJ3u6/0gRbyzazlVTvvYLsBdu3k+/R79gr085xqqd/jPGdGxWp8J+nc9i494j7glC60bJfL31oDsgNfNQPm9+vZ02jT2/v4+WlweJuwJmRdm2P49FWw/4LfMtEXGS01UNXEyILQ/R6ibGuT8/98Um3liUwb3TVgGeY+O52Zu56/0VTF+xi6tf8tSUWwszV+3hmc899d6dmtUht7DEPWkrKvHMNPLS/G1+J6GOgU/MYajPgEDfMQqOz9fu5eY3PTMDbfKeGDnfUd+xC743sPlszR7+FDBN5KH8Ir8gPC+g7/jK5wQgsB1Hi0vdKfrqJsWRGBdL79Yp7vH8/cF8xry4yO+KWOCJMvifIDuDcY+HAmwRkRAs3X7QvZwvoXGm0ArMxDWt65kirs+fZ/ld3s4vKqVp3UQyDuSzdneOXzlIeYDt+SNZzdTUFbKfjoLiMto2Lv/j6dQ2A+QUlGAMtPF5vn6tePIKS90sZp3EOPIKS/jdBytYuv2gO8NIy5Ra7DiUT8b+PEpKy9ypAotLy5j4yrc8OnM91loO5RXRrH75DB7bD+Qx+Kk5FTKZTkbOOSFwgi2nBntQe8+NNM6fNJ/1e3IqBCSOjXuPuJ/VkcISGiYnkBQf6xl0Wuafkdwb5AYwzlzgvjOpOG3LPlrMRc8vcJdv89ZIbw/IMI746zz3JCjFp0Tkyw1ZfLK6fFaZDXty3Yx5n0pOZtfu8jzvW1LiGzj9eeY69uQUMGvdXsrKLP+Yu4UNAXfmu35gW+47/wy/Zc6Jwqa9ue5n+erP+wDlJQm3v7OMP3y02i9wPK9zswptAILON/3S/K28NH8rADHeMwjnCkQwuT4nNc7xD55j6gHveIaEuBjOOLUuHy6r/g6MHZrVxVq4cepSpq/YRcc/fMJb33zPofyiSucl9y2TcX43zuuWt8dSx+cEwGn3hj25nHtGM5rUTfSr178xyFSdf5qxzu9Olc73bcfBfG54Ywl/+Xyj+xqbAmr/C4pL3d9Rq5RkducUsHT7Qffk0+Ec33UT45i9fp87yPfB6WvYk13gV2YyuGOToJ/HD6EAW0QkBE/+bwNP/m9DpJtxQmpcx3/O5SZ1yx9/vNz/UvFVfVpSJzGO577Y7HfJuLk3KHUCoRDGMVVqZNdTGOS909tBn0vLOUeLqZMYR+Panvb1a5dCozoJzFi1m0neLOvho8X85bON/GtJJg98vMbNdl53VltijeH9pTv404x1vOWtQ172fXnQ8PnavZSUWbcOGTxBvS/nMrwzg8mkLzaxaW+uO3DLKRHxDbju/2h1pTMn5BYU06xeEg2SPVOPNUiOJykuli83ZrFxb/XT2oHnSkRgjfh5nZvRvWUDv2VrvMGvM2OF7zmQM+tIik+JSIlPgF83KY4Ne3NZvzuXhNgY+ratGGA3TI5n7a4cHvnvWh74uDxL7zsjixP8xhjDsh2HeOJ/6/ndByv99pNSO5GLujf3W7bVe3Kw6/BRcguKqRUf6x6nTtmJcxK0/UA+3VLr8+q1fXj+Zz0xxr/8A8pPNgC6NK/HIxd34VB+MY994jnRcmbU2ZdTyKdr9lQobSkoLvULels1Kr/q4RusDmzfmO6p/r8HX6fUKz+Zc05sZ63b696M6d/fZVY7/Z9zTPoOaryw26k8PaY7b//iTIZ2asJdwzu6z+06fJStWUfYl1vIwPaN6NOmoXvloSqfr93r/uyUuYx5cZG7/NfDPLc/D7yVeU5BMQeOFFIvKY4GyfGs2HGYm6YurVAG4lxBuLx3KntzCtm87wgLN+/nta8y6PfYF5TZ8ptKNat3/NNYKsAWEZEaFTi1XMPk8gDz+4P53Hr2ae7jVinJTOjfmv+t2eMOlgNoVCeRhNgYtngvD0/o35o+bRq6zy+7/7yQ2jKhf2vuGt6JqdefSd2kOA7kFfHnGWuZ8Mq35Bwtpl5SPA1re4LRlNoJFTJ7u7OPstpbcrBmV457qbl1o2SaN6hFxv58vxpoX/dOW0XbxrW5rFdqpe3LLyrFWusXsD3+yXq3BjrzUMUAe3GQ2RzmbNjH+X+bz/tLM6mbFMep9T3rN0xOcGdrAbgg7VT3ZAOgWZAb0IyZ/BWLtviXOzSrl8i0Wwbw+GVp7rIjhSXUS4pjV/bRCvM7OwF6vVrxGOMJ2n3LS4Z3PoUNe3JZkXmYDs3qcMOgdn6/X4CuLerzxfp9vLxgm9/Jwd/nVrx5SlZuIet2Bw/qaifGVnifTtC2K7uAVxdmYPFkZRPjYtxbcPvOj5zasBZDOzUlMS6WJnUS+XrrAd76ZjtvLMpgzItfuccpwMU9mjO+fxv+cMEZlJZZso8WuwMzX1qwjZumLmXQE3OY9EX5wMLAoLeNT4DtZNhvGtyOv47twcD2ld8WvI/PiUr9IPM7J8TGVDsNZYf7PuGl+Vv5akt5mUZZmeWK3qkMaN+YV6/ty7AzmrnPZeUWcs5fPLcxP7dzMzo1q8f3B/P5bM0ebnhjSYX9O5xjGzxlS2Vl1q+spl2T2iTExVSo595/pIg9OQU0rpNIckKcu+xx791anePIufrhlFf9acY6v6tkUD4DSbDvwQ+lAFtERGrUqK6n+D2um+T/h35sn1buz20qCUCT4mPc6fAA7hrRiZcm9nEf168Vz+vX9eWK3v7b+mbWXrymNw9f3NWtZ25cJ5H9Rwr55/xtzNuYxbRlO6mTGOeeADRMTuDvV/finRv6sez+8xjcsQm7swvYcSifAac1IsZ47hoHkJwQR2Nvttspqwh0IK+Iy3u1cLO4wezOLqDtvTOZ4VMbnlNQ7F52dzLmqQ09AXPz+sEzbde+upi13uC/blI8p3rXa5Ac706zBtC5eT33ZANgRJfy39X9F3YGYPXOHLc9zmdXOyGO2BjD2L6t+PvVvdxtxvVthbVw29vfuYEplGeB2zWuTXJ8LFPmbeXRmeuJMbDxT6M4/ZS67Mst5OutBxnR5RTqJ8cz9foz3e0fuyyN9NYp7n5GdjnFHfjq8L2l/cxVu/0CQl91EuPc+nBHYAa6oLgMY4x7jID/7BW1E8pLIk5tUItvtx3kvg9X88DHa1iccYh3vi0/OXSOd+d3dsGkBRXGEhwtLuWZzze6A/FWBNxptJbP6zluOfs06iXFM7LrKYzo0oyhnSqWNTRv4JPBDpKVTYyPDekGTf9asoMtWXl0bVEPoMIxntqwFk3rJtLOp7xqVNdTSG2YTMsUz/v++9wtfllqp0xnUIfGxBj8vt8zVu3m4xX+ZS/N6iWRkpzgVzoDnhmKPl2zl5YpyX5zWGd4B+uO798GKJ/15PRTPO/hy41Z/O7f/lc3Xp6Yzoguzfy+B8dKAbaIiNSoxy5LY+3DI9zH/dql8MglXd3Hzh9ggI5N69K+aR1+N7IT024dwGd3DOZnZ7YitWEyd55XHiwnx8f61X3GxBiGdGzC02O6u3+4z2ybwm3ndHDXC6wFb1Q7wS1rcGzYm0t9bzlFw+QEuqU2oP9pjWhYO4EzTq3LjoP57MkpoE+bFEZ0OcWtLa6dEOeWwqS3bsjGP43i1Wv7EGhQh9BrO8f0TmVc35YszjhEUUkZ56eV/9FPqZ3A4vvO5cNfnlXtfuolxdHDW86Rc7TYb4YGJzOe6K2pdcoNTj+lboUTo4S4GPfkoLbPZ+8E5wDDvYHJrHUVb6XdMqUWDWsnUCshzq3PL7Oe/XbyTv0HcMOgdgAkxcfyq3Pa8+9bBjCubyt6ty7PaL9wdS/3BAA8Nwdp0bD8OFq/J9ed4s8x7+6h3HL2aW6A5ajsJAWgUZ0Epn23k3W7c/xu7+77/q/u2yrYpq56boDtyUI7ZT614mP52Zmt/E4ULv/HV7yyYBtP/G89CXExTLt1ACO7nMK4vv4nE2//4kwaeE8EjTFMHp/O45d3c593jpUGtRL4+Jdn8fkdg2np8/k45m3MqlCjHoxzxeBcb6Y6sITCGMPTY7rzzFU9uKDbqTxySVf+cU1vAPfqie9g5OsHtmWk9/ga1fVUUrxlWb4lLXe8t8LvNU6pn+Qef74DQB0Pje7i93tx9G7dEGM8U0zGxRi/MRi+Xvl5OsPOaMbk8elB9/NDKcAWEZEa0a5xbe4a3pG42Bj30i14/hhf2rOF32OHE9zeenZ7erVqSMdmdXn00jRiYwy3ndPeXS8uNqbCPMEOp964zBtIdvDOGhGYV25UJ8GtlZ1+21lM7N+a+y/s7GZCfQdyAYzv15oYY7AWWqYk8+QV5QFNcmJ5za5zKfu0xv6zVTRMjqdri/p+yyqbLQOgT5sU0n0G+/kGNckJcTSpm+hXz333iE78+dKu3D2ikztTC3gyqDcMaseA0xoxtk8rv7mgnYDFmTO5TlIc3/zfMN67qb9frTx4Zp1wZgHxPVlJ9N6Bs2ndRE5rUvnsC91aeIL37CAD+073Bthdmtejls++7xzeyQ2s+5/WiD9e1JkFvx9KbIzxC4K+umdY0NuAt/AppWnVKJnfjzzd/b3+fEAboHxAW7CyAKfeedTf5vtlbX1P7sakp/L2DWdW2NZRr1ZchbaA5/f16KVp/GJQO3cg6uqdOTz837Vs3neEGwe1o1erhrw4vrdf4AmeKfcCOce9b/vq1Yqje8sGdGhWt8orJ84x73sSE8z1A9vy3LieQacsHdyxCT1aNuCFn/VifL/y4y/wfYPnpKNlSjJrHhrBuL4taVzH07Y2jZN5blxPv+0dKckJ7ntITfHfZ3ysoU3j2hUC41rxsbRoUIuzTvOU0TRIjq/wvXa0bVxxdpnjEVKAbYwZaYzZYIzZbIy5J8jzicaY97zPf2OMaePz3L3e5RuMMSN8lmcYY1YZY5YbYyovyhERiQIPXNSZBy7qXP2K4qqdGMdt53QI+pwTADiXtVulJFeaWXIEXtavjPNH2Bn3d/MQT413a5/p8QCaem9bbgx0bFaXhy7uyvUD21a639SGye6+2jRK9it1SU4oz6i3aOB5Hd/L8zEGBnZoUuGkoF3j2sTHGv51U3+uPauN33PnnNGUi3s0583rzyQuxrgzVkB58B/nk8nrf1ojrj6zNb8c2p6HL+7K7d5BYbUT46iVEMvbN/Tj3M7N3AD7Z2e2coNMJ4NdNzGOZvWSqF8r3g26fTWuWzGD3aFpHWonxPL0mO5uVjWYs7y1wsFKaJrWS+LFa3r5lYUEio0xXHtWWzcT7KterTh3wOgfLiifIeTMIIMlHX+8qDNbHj2fPm1SvO+jboV1nM/Q4ZRI+J4EGGMYcFpjHrssjS7N6/ldaYDyDHaD5Hi/gaFOLXD7pnXY+tgF3HleRz68dYD7fAef6QR9j/2/X93LnU/cl3OiA+Wfse8y330EXp0Y2KExCXEx/PWqHsy562y/59K8J4XtGtemblI8F3Vv7ldmVJ1m9SueuDgnHbW95TrOyVz9Wp79+17hcoL+mBjjfrcDTzicizKBV6mck47hXTzfnaruIBrsROB4VJsDN8bEAi8A5wGZwGJjzHRr7Vqf1a4HDllr2xtjxgJPAFcZYzoDY4EuQHNgljGmo7XWeYdDrbXBi6RERKJIl+b1q19JfpAVDwx3A5XZdw4JaZsYU/0MIk7g62SwR3Q5hS2Pnl8huE1L9fxOrcUvYHCCkmAB5i+HtqdL83oVMn3JCXFu4Fo70bN9XGwMp9ZP4uxOTejVqqEbUIGnLGFXdgHdUxtQXGrp2zbFMzOFt6b7b2N7uCUnAzs0ZvOj5wOeE5PKbq9dJyB7l+Jk8gM+MGcA4uW9WrgBuhOwV3dp3GmT72fZsHYCax4e6T6+49yOPDtrY4VtRwYEdU+P6e7WJXueP7XK166KMYZfndOe52Zv5vqBbfl4+S5W7cymb9sUdy7xYNvEGtwAu2OzulzTrzU3v7mUdO/v9+YhpzGubyu6P2FfzzUAABNqSURBVPQZAD1bNmT1zhwKg9xEaVzfVozr24rCklLOT9vLM59vZGtWnhv0GWP4+Jdn0eaeGQAVZv/4VUAw375p8Izq+WmVf05xMYaRXU9x65njY4OflP7jmt5c/PwCt9b7rNMa8/LEPhW+IyseGM7LC7examd2hVljQuUb5DsCx2E4x5XvCePU6/syc9UeHrm4izvrinMi2LFZXb7yGXjrfNdrB9SqOwM7uzT3nBg5A0RbpST7zTLy71sGVJrZPlahFJn0BTZba7cCGGPeBS4GfAPsi4EHvT9/ADxvPKdKFwPvWmsLgW3GmM3e/S0KT/NFRH4cCzZ5cgEDO1Q+Yl9+mPo+l7TjggSzwXx97zC/uXm/vPvsCtk0Z25r3wA5WDlJr1bBL4dfN7AtB/OK/MosHAlxMW6dMcDt57Rn0uzN1E6IdTN9aT5lIIvuHRb0Nabdehbr9+TQ+dR6HPbOGJEUH8ukcT1pXDuBAZXMDDH7riFBbyEPFbN3yd5guThgvmvnRMA32+wEQdXNfugEQoEzw/i6fVh7LuvVgudmb2JU2qmkJCdw+Gixm328e0Qn8gpLKgxIPRaTx/d2Z3q5c3gn7hzuX7pQ3VUR8NSGX5XeknNOb8rADo3Z+uj5fqU79QNmDwHP3T0rkxgXy4XdmrNix2G2Zm2rkNV//+b+5BeVElNJidMvh57GC3O2cFoT/wB7/u+GVvtenBMx5+6mgd+Nf98ywK0lf3pMd857dp73/ZT4fUd+PawDf/tiE3WT4twZTdqF8FlW5uYhp/Hil1s888UfPOo3IBXgsl4t+HDZTjr6XEUY1KGJO2bBCVadgbPDuzRjx8F8+rZN4bFP1tP/tEaAp1QrcL8AnQLq7j/9zWB2ZR9lmHe2k+pKY45FKAF2C2CHz+NMIPAajruOtbbEGJMNNPIu/zpgW6fwzgKfGWMsMNlaO6XalmzYAGefHUKTRUTC67nOVwEwcO17EW7JiWve3UPdTNOxalovyW82hNZB7rjWrUV9JvRvzS8GtqtyX+0a16ZeUhy3Dm3vt7xOYhwPju4SUnvuOK8jd5zXEWMMY9JT6d2mYYXAKJhT6idxindwne/7GR0wP3OgpnWT3NKWQIEZbCd7WRJQkuGs5zs48XcjO/HLt76rUEP94a0DOJzvmcWkVnwszRsk8fKCbQyuYrCmMcZbo9496PO/DPi8j0dlsz3cPOQ0fvn2d3RsVpdfDj0taPmHwxjDEz719MEC3yvTUyksKXMHYzp3c6zK70eezsQBbSrUsjsZ88rceV4nbhvaoUJw3DKl+td03H/BGaQkxzO0U1O/5Z5A0hNMdmhWl8cuS+PeaasqjAVwjmuAy3ul8u7i77nEZ9zED3XPqNP5zbkd+L8PV7Hj4M4K018O6tCEb+8b5jeFZzD/d/7pdGxWl35tGzHAW1fdt20Kp3mz/c5JdaPaCTxwUWcu7Ob5PjnH/Ejv8VIrIZa2YbhbY1VCCbCDnWIF9pCVrVPVtmdZa3cZY5oCnxtj1ltrK9z83RhzI3AjQLfE45+XUEREao5vn92qlf/sCr43y6hJcbExPHxx12rXi4kxrHxwRLXrVcW3rtUYE1JwHW4JcTEUlZRVKO9o5g3EUwNmj5gyoTdfrNvnF6gP6tAk6GfRM0iWP+PxC8LR7Bp1QbdTuaCbp513jzj9uPfne7Lw71sG0DOEcom42Jig9eLViYkxfjXex6JpvSQeCuE7cEXvVA7nFzNxQMWrNY601Pqsf2TUcbUHPNn0mwafxlebD3D26RVP0Co7cfTVvmld7hnl//v0PUadcqgYAxf38D8h2PLo+X53gK3sCkK4hBJgZwK+88OkArsqWSfTGBMH1AcOVrWttdb5f58x5kM8pSMVAmxvZnsKQHp6umXu3BCaLCISZpO9lW1/v+XYtg9xgN6JrkKfLTVu+m1nMW9jVoWa8QHtGzNlfG/ODshipjZMZqJ3cKP8cDVRThAp8bEx3OJzo6ea1umUunz9f8HLpsLBqdUONiA6WJnY5PG9K9Rth0soe10MdDDGtAV24hm0+LOAdaYDE/HUVl8BzLbWWmPMdOBtY8wzeAY5dgC+NcbUBmKstbnen4cDD1fXkI17cxny1BzKrKWwuAxjINYYYmIMMcZgjGeOz7pJ8SQnxFIrIZa8whIKS8pIiI2huLSMxLhYDuQVUWYtiXExJMZ5pnoqs5BfVEJcTAwJcTEYPEXzZRZKyyzWWiye0cBHCkvIKSimtMy6rx8X4/k/1hj3lxgT47lda0JsDAUlpdRNjCen4P/bu/cYSarrjuPfU1XdPY/dZQHzxgoYr4iJFBOzIljOH4Q4DrEcW4pQgpXIVoSEImHJkSJFtiJFsv/zP8GKZFtxBCIiD16JFbx/mGBwLCuyIbMxYBa88uJsBNoVG8LAPmamux4nf9xbve1ldqbj6Zl+1O8jtbr7dnXNPd3VZ049b06aGBcuhBHCiqqirDzc3ClLZyUvuXzPHKt5STevaGcJRRkuel+5084SunlF5c58O2UuS1krSvK4yyVLk/4uqcodd/AYSx2Tx/bKnTQxsjRceipLrL81pFtUZKnRyVKKsqJXOlXltLIQpwNzWUpRVaz0Ss70Ctppwq65Fr2iIk0gTRJacf6Vw/KZHq00oZVavE9oZQnuYXSrLLFwLKZDKzMMY3mlR5aGPu2ey+gV4TNb7KSs9EpOdwuMkCjSxM7e4nfTLSqMMFBFVYUfYFk5Vby/YL7VvybrSq+kkyXMt1LSxDjdLWilRpaE7xDCZ5QmoS1NjKKqWO2VVH62hmqnYfSvdprQaSXMZSmdVkJixpluwcm1gqpy5topeYyrrJxuUeE4i+2Myp0z3ZL5dkrlTlGGPi+2M94402Uhfvf18rbSK+kWJXvmWv2tH/XeeMfPPvbw/GdfD+rddvWu47ys6BUVeekUlZNY2NVW/816XuGen923ZWHY4nYatsa00qS/zNX39Vs8fheDbOC34x62SHj9N+Pvsf77uzthdLjBzyJNjMTACN/Xal6yvNIjsdAecoZhA7/VbODSXx5/++E347x8/BRpYvzuV/99s1QlsqN+8fI977i2c+0jIxgwQ2Ra1FcXGfYqJ6MYUOZ8Ni2w4zHVnwGeAFLgfnc/ZGZfBJbc/XHgPuDBeBLjm4QinDjdI4QTIgvgHncvzewy4BtxDSMD/sHdv7VZXzpZ2r9Y/kI77RdLlYfCzwmFwVsrOb0iFH2X7u4w10rJY4G61iv5wC/sJU2Mbh6KyNKdxIz5VkJZnR1N6Ow/4VDIVw5vr+bsmcvYM98iSyz8/bo4rgvlKhYwHvq32iuZa6Usr/TYd9kuiso5uZrTjgVmmlq/aEstFKOvn+yyey6jnYbRy7Ik3KexyOhkCYaxVpSs5WH+7TTBgW5R8b+nu/2+m9WFxkBRYfSLj8pD8WSE2IvSmV/ImMsSispZy0t2dbJYwIbj+erhRNfyksVOuB7rQjujW5Sc7pahL+7klVNWoUDD4bpLQvx5GVYu8sJZjQMfXLjQpoyvEYfSrTxc+zUvK7LEWOmV7J4LBd6ZbsFFi+3+cWl5UfWL5iIWRkXp7InFYjevSBJoJaHQTeOK2Ztneiy0U9zhwr1tukVYsVkryn7hm5dV/xiuev6reUlRVrTiNX6TxPoDOLy1knPdJYv9ormbV7wZV+wW2hmX7+nQyVJW8pJWYpzqFrSzpD8U7+m1cMLJlXvDilZd/CVmnFzLufbiRUr3WPzWI461aWcJyyt5/yoDxtk1+fCY+Nj6B3BZXNbdw9UPwt8IKy3tLMTWzpJ4/V/nVLegV1TvmJcBloTnddF95QVz5JWz1is5lYeY6uWw/x7Cilgns/4868L/TK+gkyX94rxenutY6vhOruaUfrbQ39VJ4woJuFd0C6eVJuHasf0VzXeubPbKilNrRfx9xN+NhZWpxMIKyHw7fEYyBJ03IyI76DZg//W/R3rS4NYvjLUvNjii06Tbv3+/Ly3pktkisvNe+Z8w4MTPe4ytmR109/2j7NOk2797ty/ddNO4uyEiDfLKXDiE57q15S3Nx7773S3l7O058EREZMaM4+S1qXf99ei8GRHZSSM7onyLeyo1VLqIyBC+/dLrfPul18fdDRER2cCk5GptwRYRGcLffO+nAHx4YLhqERGZLJOSq7UFW0RERERkhFRgi4iIiIiMkApsEREREZERUoEtIiIiIjJCOslRRGQI9/7+jePugoiIbGJScrUKbBGRIVy5d37cXRARkU1MSq7WISIiIkP45vPH+Obzx8bdDRER2cCk5GptwRYRGcLf/eC/Afid91855p6IiMj5TEqu1hZsEREREZERUoEtIiIiIjJCKrBFREREREZIBbaIiIiIyAjpJEcRkSF87Q9vGncXRERkE5OSq1Vgi4gM4aLF9ri7ICIim5iUXK1DREREhvDo0qs8uvTquLshIiIbmJRcrQJbRGQIjx18jccOvjbuboiIyAYmJVerwBYRERERGSEV2CIiIiIiI6QCW0RERERkhFRgi4iIiIiMkC7TJyIyhAf+6OZxd0FERDYxKblaBbaIyBDm2+m4uyAiIpuYlFytQ0RERIbw4PeP8uD3j465FyIispFJydUqsEVEhnDgheMceOH4uLshIiIbmJRcrQJbRERERGSEhiqwzex2MztsZkfM7HPrvN4xs4fj68+Y2TUDr30+th82s98adp4iIiIiItNo0wLbzFLgK8BvAzcAnzSzG86Z7C5g2d3fC9wLfCm+9wbgTuCXgNuBr5pZOuQ8RURERESmzjBbsG8Gjrj7T929BzwEfOKcaT4B/G18/BjwG2Zmsf0hd++6+38BR+L8hpmniIiIiMjUGeYyfVcBrw48fw341fNN4+6Fmb0NXBzbf3DOe6+KjzebJwBmdjdwd3x62swOD9HnSfcu4I1xd2KMmhx/k2OHGYj/kT/+ud96/Qi7MbFmNGfDDCy7W6DYm2tq499Crq5tKWcPU2DbOm0+5DTna19vy/m58wyN7l8Hvr5RB6eNmS25+/5x92Ncmhx/k2OHZsdvZkvj7sNOmMWcDVp2FXszNTn+rebsYQ4ReQ1498Dzq4Fj55vGzDLgAuDNDd47zDxFRERERKbOMAX2fwD7zOxaM2sTTlp8/JxpHgc+HR/fATzt7h7b74xXGbkW2Ac8O+Q8RURERESmzqaHiMRjqj8DPAGkwP3ufsjMvggsufvjwH3Ag2Z2hLDl+s743kNm9gjwElAA97h7CbDePEcf3sSaud2n/09Njr/JsUOz429y7LOgyd+fYm+uJse/pdgtbGgWEREREZFR0EiOIiIiIiIjpAJbRERERGSEVGBvAzO738xOmNmLA20XmdmTZvaTeH9hbDcz+6s4ZPwLZvaB8fV868zs3Wb2HTN72cwOmdlnY3tT4p8zs2fN7PkY/xdi+7Vm9kyM/+F4ci/xBOCHY/zPmNk14+z/KMTRWn9oZgfi80bEbmZHzexHZvZcfXmnpiz30045WzlbObt5ORu2N2+rwN4eDxCGhh/0OeApd98HPBWfQxgufl+83Q18bYf6uF0K4E/d/X3ALcA9ZnYDzYm/C9zm7u8HbgRuN7NbgC8B98b4l4G74vR3Acvu/l7g3jjdtPss8PLA8ybF/uvufuPAdWObstxPuwdQzlbOVs6uNSl22K687e66bcMNuAZ4ceD5YeCK+PgK4HB8/NfAJ9ebbhZuwL8Av9nE+IEF4D8Jo5S+AWSx/YPAE/HxE8AH4+MsTmfj7vsWYr46JqTbgAOEwaaaEvtR4F3ntDVuuZ/Wm3J2Px7lbOXsRsQe49i2vK0t2DvnMnc/DhDvL43t6w1FfxUzIO4++hXgGRoUf9zd9hxwAngSeAV4y92LOMlgjP344+tvAxfvbI9H6svAnwFVfH4xzYndgX81s4MWhguHBi33M6hx351ytnI2zcrZsI15e5ih0mV7DTMU/dQxs13APwF/4u4nzdYLM0y6TttUx+/hWu83mtle4BvA+9abLN7PTPxm9jHghLsfNLNb6+Z1Jp252KMPufsxM7sUeNLMfrzBtLMWe5PM5HennK2cXTevM+nMxT5g2/K2tmDvnNfN7AqAeH8its/csPFm1iIk6r9393+OzY2Jv+bubwH/Rjiuca+Z1Su0gzH244+vX0AYrGkafQj4uJkdBR4i7HL8Ms2IHXc/Fu9PEP5J30wDl/sZ0pjvTjk7UM5uVs6G7c3bKrB3zuBw8p8mHOdWt38qnp16C/B2vWtiGlnY7HEf8LK7/+XAS02J/5K4FQQzmwc+TDh55DvAHXGyc+OvP5c7gKc9Htw1bdz98+5+tbtfQxjN9Wl3/wMaELuZLZrZ7vox8BHgRRqy3M+oRnx3ytnK2U3M2bADeXvcB5jP4g34R+A4kBPWeO4iHKf0FPCTeH9RnNaArxCO+foRsH/c/d9i7L9G2GXyAvBcvH20QfH/MvDDGP+LwF/E9vcAzwJHgEeBTmyfi8+PxNffM+4YRvQ53AocaErsMcbn4+0Q8OexvRHL/bTflLOVs5Wzm5WzB+LctrytodJFREREREZIh4iIiIiIiIyQCmwRERERkRFSgS0iIiIiMkIqsEVERERERkgFtoiIiIjICKnAFhEREREZIRXYIiIiIiIj9H9kMQJ0P747uQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not PERMUTE:\n",
    "\n",
    "    # The loaded `df_train` set contains both the training and the validation set. So we need to split.\n",
    "    df_val = df_train.loc[df_train['period0'] == 1]\n",
    "    df_train = df_train.loc[df_train['period0'] == 0]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ##### Step 2: Choose feature and standardize\n",
    "    Before data sets are fed to a network, all their features need to be standardized to \n",
    "    have zero mean and unit standard deviation.\n",
    "    \"\"\"\n",
    "    use_fea = [x + '_t' for x in ori_fea] + ['cp_int']\n",
    "\n",
    "    scaler = StandardScaler().fit(X=df_train[ori_fea])\n",
    "    df_train, df_val = nw.standardize_feature([df_train, df_val], scaler, ori_fea)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ##### Step 3: Build a network and train it\n",
    "    \"\"\"\n",
    "    sub_res_paths = {\n",
    "        'ckp': sub_res_dirs['ckp'] + 'bestcp.h5',\n",
    "        'history': sub_res_dirs['history'] + 'history.csv',\n",
    "        'plot': sub_res_dirs['plot'] + 'losscurve.png'\n",
    "    }\n",
    "    history = nw.train_net_core(df_train, df_val, use_fea, hypers, sub_res_paths)    \n",
    "    nw.plot_history(history, sub_res_paths['plot'], df_train, df_val)\n",
    "    \n",
    "    for i in range(NUM_TEST):\n",
    "        df_test = mc_sets[i]\n",
    "\n",
    "        [df_test] = nw.standardize_feature([df_test], scaler, ori_fea)\n",
    "        delta = nw.test_net_core(df_test, use_fea, sub_res_paths)\n",
    "    \n",
    "        cm.store_pnl(\n",
    "            df_test, delta,\n",
    "            pnl_path=sub_res_dirs['pnl'] + f'pnl{i}.csv'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare permutations.\n",
    "\"\"\"\n",
    "if PERMUTE:\n",
    "    train_permutes, val_permutes, test_permutes = [], [], []\n",
    "    for i in range(NUM_TEST):\n",
    "        # the union of train and test\n",
    "        df_permute = df_train.append(mc_sets[i], ignore_index=True, sort=False)\n",
    "        df_permute = cm.permute_core(df_permute, 0, random_seed=i)\n",
    "\n",
    "        df_train_permuted = df_permute.loc[df_permute['period0'] == 0]\n",
    "        df_val_permuted = df_permute.loc[df_permute['period0'] == 1]\n",
    "        df_test_permuted = df_permute.loc[df_permute['period0'] == 2]\n",
    "\n",
    "        train_permutes.append(df_train_permuted.copy())\n",
    "        val_permutes.append(df_val_permuted.copy())\n",
    "        test_permutes.append(df_test_permuted.copy())\n",
    "    del mc_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if PERMUTE:\n",
    "    use_fea = [x + '_t' for x in ori_fea] + ['cp_int']\n",
    "    for i in range(NUM_TEST):\n",
    "        \"\"\"\n",
    "        ##### Step 2: Choose feature and standardize\n",
    "        The difference of permuating version and the above version is:\n",
    "        we standardize for each permutation.\n",
    "        \"\"\"\n",
    "        scaler = StandardScaler().fit(X=train_permutes[i][ori_fea])\n",
    "        train_permutes[i], val_permutes[i] = nw.standardize_feature([train_permutes[i], val_permutes[i]], scaler, ori_fea)\n",
    "        \n",
    "        \"\"\"\n",
    "        ##### Step 3: Build a network and train it\n",
    "        \"\"\"\n",
    "        sub_res_paths = {\n",
    "            'ckp': sub_res_dirs['ckp'] + f'bestcp{i}.h5',\n",
    "            'history': sub_res_dirs['history'] + f'history{i}.csv',\n",
    "            'plot': sub_res_dirs['plot'] + f'losscurve{i}.png'\n",
    "        }\n",
    "        history = nw.train_net_core(train_permutes[i], val_permutes[i], use_fea, hypers, sub_res_paths)\n",
    "        nw.plot_history(history, sub_res_paths['plot'], train_permutes[i], val_permutes[i])\n",
    "\n",
    "        \"\"\"\n",
    "        Test the network for only one permuted test set.\n",
    "        \"\"\"\n",
    "        [test_permutes[i]] = nw.standardize_feature([test_permutes[i]], scaler, ori_fea)\n",
    "        delta = nw.test_net_core(test_permutes[i], use_fea, sub_res_paths)\n",
    "        cm.store_pnl(\n",
    "            test_permutes[i], delta,\n",
    "            pnl_path=sub_res_dirs['pnl'] + f'pnl{i}.csv'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'{sub_res}additional_paras.txt', 'w+') as file:\n",
    "    file.write('The following is network setup.\\n')\n",
    "    file.write(f'Date and time = {datetime.datetime.now()}\\n')\n",
    "    for n, x in [\n",
    "        ('Random seed', seed),\n",
    "        ('Features used', use_fea),\n",
    "        ('Learning rate', hypers['lr']),\n",
    "        ('L2 regularization alpha', hypers['reg_alpha']),\n",
    "        ('Nodes per layer', hypers['nodes_per_layer']),\n",
    "        ('Number of training epochs', hypers['epochs'])\n",
    "    ]:\n",
    "        file.write(f'{n} = {x}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
